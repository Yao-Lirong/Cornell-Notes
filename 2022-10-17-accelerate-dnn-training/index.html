<!DOCTYPE html><html lang="en" class="" style="scroll-padding:60px"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width,initial-scale=1"/><title>Accelerate DNN Training - Incomplete CS Notes @ Cornell</title><meta property="og:title" content="Accelerate DNN Training - Incomplete CS Notes @ Cornell"/><meta name="generator" content="mystmd"/><meta name="description" content="This is a complete collection of course notes I&#x27;ve taken when studying CS at Cornell University"/><meta property="og:description" content="This is a complete collection of course notes I&#x27;ve taken when studying CS at Cornell University"/><meta name="keywords" content="Cornell, CS, Yao Lirong"/><meta name="image" content="/cornell-notes/build/cornhell-37b881e150badb60bb90a0054b1665ba.png"/><meta property="og:image" content="/cornell-notes/build/cornhell-37b881e150badb60bb90a0054b1665ba.png"/><link rel="stylesheet" href="/cornell-notes/build/_assets/app-5WKS5EPQ.css"/><link rel="stylesheet" href="/cornell-notes/build/_assets/thebe-core-VKVHG5VY.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jupyter-matplotlib@0.11.3/css/mpl_widget.css"/><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css" integrity="sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ" crossorigin="anonymous"/><link rel="icon" href="/cornell-notes/favicon.ico"/><link rel="stylesheet" href="/cornell-notes/myst-theme.css"/><script>
  const savedTheme = localStorage.getItem("myst:theme");
  const theme = window.matchMedia("(prefers-color-scheme: light)").matches ? 'light' : 'dark';
  const classes = document.documentElement.classList;
  const hasAnyTheme = classes.contains('light') || classes.contains('dark');
  if (!hasAnyTheme) classes.add(savedTheme ?? theme);
</script></head><body class="m-0 transition-colors duration-500 bg-white dark:bg-stone-900"><div class="fixed top-1 left-1 h-[0px] w-[0px] focus-within:z-40 focus-within:h-auto focus-within:w-auto bg-white overflow-hidden focus-within:p-2 focus-within:ring-1" aria-label="skip to content options"><a href="#skip-to-frontmatter" class="block px-2 py-1 text-black underline">Skip to article frontmatter</a><a href="#skip-to-article" class="block px-2 py-1 text-black underline">Skip to article content</a></div><div class="bg-white/80 backdrop-blur dark:bg-stone-900/80 shadow dark:shadow-stone-700 p-3 md:px-8 sticky w-screen top-0 z-30 h-[60px]"><nav class="flex items-center justify-between flex-nowrap max-w-[1440px] mx-auto"><div class="flex flex-row xl:min-w-[19.5rem] mr-2 sm:mr-7 justify-start items-center shrink-0"><div class="block xl:hidden"><button class="flex items-center border-stone-400 text-stone-800 hover:text-stone-900 dark:text-stone-200 hover:dark:text-stone-100"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" width="2rem" height="2rem" class="m-1"><path fill-rule="evenodd" d="M3 6.75A.75.75 0 0 1 3.75 6h16.5a.75.75 0 0 1 0 1.5H3.75A.75.75 0 0 1 3 6.75ZM3 12a.75.75 0 0 1 .75-.75h16.5a.75.75 0 0 1 0 1.5H3.75A.75.75 0 0 1 3 12Zm0 5.25a.75.75 0 0 1 .75-.75h16.5a.75.75 0 0 1 0 1.5H3.75a.75.75 0 0 1-.75-.75Z" clip-rule="evenodd"></path></svg><span class="sr-only">Open Menu</span></button></div><a class="flex items-center ml-3 dark:text-white w-fit md:ml-5 xl:ml-7" href="/cornell-notes/"><div class="p-1 mr-3 dark:bg-white dark:rounded"><img src="/cornell-notes/build/cornhell-37b881e150badb60bb90a0054b1665ba.png" class="h-9" height="2.25rem"/></div><span class="text-md sm:text-xl tracking-tight sm:mr-5 sr-only">Made with MyST</span></a></div><div class="flex items-center flex-grow w-auto"><div class="flex-grow hidden text-md lg:block"></div><div class="flex-grow block"></div><button type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R74op:" data-state="closed" class="flex items-center h-10 aspect-square sm:w-64 text-left text-gray-400 border border-gray-300 dark:border-gray-600 rounded-lg bg-gray-50 dark:bg-gray-700 hover:ring-blue-500 dark:hover:ring-blue-500 hover:border-blue-500 dark:hover:border-blue-500"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="p-2.5 h-10 w-10 aspect-square"><path fill-rule="evenodd" d="M10.5 3.75a6.75 6.75 0 1 0 0 13.5 6.75 6.75 0 0 0 0-13.5ZM2.25 10.5a8.25 8.25 0 1 1 14.59 5.28l4.69 4.69a.75.75 0 1 1-1.06 1.06l-4.69-4.69A8.25 8.25 0 0 1 2.25 10.5Z" clip-rule="evenodd"></path></svg><span class="hidden sm:block grow">Search</span><div aria-hidden="true" class="items-center hidden mx-1 font-mono text-sm text-gray-400 sm:flex gap-x-1"><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none hide-mac">CTRL</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none show-mac">âŒ˜</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none ">K</kbd><script>
;(() => {
const script = document.currentScript;
const root = script.parentElement;

const isMac = /mac/i.test(
      window.navigator.userAgentData?.platform ?? window.navigator.userAgent,
    );
root.querySelectorAll(".hide-mac").forEach(node => {node.classList.add(isMac ? "hidden" : "block")});
root.querySelectorAll(".show-mac").forEach(node => {node.classList.add(!isMac ? "hidden" : "block")});
})()</script></div></button><button class="theme rounded-full aspect-square border border-stone-700 dark:border-white hover:bg-neutral-100 border-solid overflow-hidden text-stone-700 dark:text-white hover:text-stone-500 dark:hover:text-neutral-800 w-8 h-8 mx-3" title="Toggle theme between light and dark mode" aria-label="Toggle theme between light and dark mode"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="h-full w-full p-0.5 hidden dark:block"><path fill-rule="evenodd" d="M9.528 1.718a.75.75 0 0 1 .162.819A8.97 8.97 0 0 0 9 6a9 9 0 0 0 9 9 8.97 8.97 0 0 0 3.463-.69.75.75 0 0 1 .981.98 10.503 10.503 0 0 1-9.694 6.46c-5.799 0-10.5-4.7-10.5-10.5 0-4.368 2.667-8.112 6.46-9.694a.75.75 0 0 1 .818.162Z" clip-rule="evenodd"></path></svg><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-full w-full p-0.5 dark:hidden"><path stroke-linecap="round" stroke-linejoin="round" d="M12 3v2.25m6.364.386-1.591 1.591M21 12h-2.25m-.386 6.364-1.591-1.591M12 18.75V21m-4.773-4.227-1.591 1.591M5.25 12H3m4.227-4.773L5.636 5.636M15.75 12a3.75 3.75 0 1 1-7.5 0 3.75 3.75 0 0 1 7.5 0Z"></path></svg></button><div class="block sm:hidden"></div><div class="hidden sm:block"></div></div></nav></div><div class="fixed xl:article-grid grid-gap xl:w-screen xl:pointer-events-none overflow-auto max-xl:min-w-[300px] hidden z-10" style="top:60px"><div class="pointer-events-auto xl:col-margin-left flex-col overflow-hidden hidden xl:flex"><div class="flex-grow py-6 overflow-y-auto primary-scrollbar"><nav aria-label="Navigation" class="overflow-y-hidden transition-opacity ml-3 xl:ml-0 mr-3 max-w-[350px] lg:hidden"><div class="w-full px-1 dark:text-white font-medium"></div></nav><div class="my-3 border-b-2 lg:hidden"></div><nav aria-label="Table of Contents" class="flex-grow overflow-y-hidden transition-opacity ml-3 xl:ml-0 mr-3 max-w-[350px]"><div class="w-full px-1 dark:text-white"><a title="Incomplete CS Notes @ Cornell" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30 font-bold" href="/cornell-notes/">Incomplete CS Notes @ Cornell</a><a title="INFO1998 Intro to Machine Learning" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/cornell-notes/2020-10-02-info1998-intro-to-machine-learning">INFO1998 Intro to Machine Learning</a><a title="CS2024 C++ Programming" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/cornell-notes/2020-09-07-cs2024-c-programming">CS2024 C++ Programming</a><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="CS2112 Object-Oriented Design (Honors)" class="block break-words rounded py-2 grow cursor-pointer">CS2112 Object-Oriented Design (Honors)</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R16p8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R16p8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="CS3110 Functional Programming" class="block break-words rounded py-2 grow cursor-pointer">CS3110 Functional Programming</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R1ep8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R1ep8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="CS4780 Intro to Machine Learning" class="block break-words rounded py-2 grow cursor-pointer">CS4780 Intro to Machine Learning</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R1mp8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R1mp8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="CS4787 Principles of Large-Scale Machine Learning" class="block break-words rounded py-2 grow cursor-pointer">CS4787 Principles of Large-Scale Machine Learning</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R1up8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R1up8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><a title="CS4820 Intro to Analysis of Algorithms" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/cornell-notes/2020-10-13-cs4820-intro-to-analysis-of-algorithms">CS4820 Intro to Analysis of Algorithms</a><a title="ORIE4350 Game Theory" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/cornell-notes/2022-02-08-orie4350-game-theory">ORIE4350 Game Theory</a></div></nav></div><div class="flex-none py-6 transition-all duration-700 translate-y-6 opacity-0"><a class="flex mx-auto text-gray-700 w-fit hover:text-blue-700 dark:text-gray-200 dark:hover:text-blue-400" href="https://mystmd.org/made-with-myst" target="_blank" rel="noreferrer"><svg style="width:24px;height:24px" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100" stroke="none"><g id="icon"><path fill="currentColor" d="M23.8,54.8v-3.6l4.7-0.8V17.5l-4.7-0.8V13H36l13.4,31.7h0.2l13-31.7h12.6v3.6l-4.7,0.8v32.9l4.7,0.8v3.6h-15
          v-3.6l4.9-0.8V20.8H65L51.4,53.3h-3.8l-14-32.5h-0.1l0.2,17.4v12.1l5,0.8v3.6H23.8z"></path><path fill="#F37726" d="M47,86.9c0-5.9-3.4-8.8-10.1-8.8h-8.4c-5.2,0-9.4-1.3-12.5-3.8c-3.1-2.5-5.4-6.2-6.8-11l4.8-1.6
          c1.8,5.6,6.4,8.6,13.8,8.8h9.2c6.4,0,10.8,2.5,13.1,7.5c2.3-5,6.7-7.5,13.1-7.5h8.4c7.8,0,12.7-2.9,14.6-8.7l4.8,1.6
          c-1.4,4.9-3.6,8.6-6.8,11.1c-3.1,2.5-7.3,3.7-12.4,3.8H63c-6.7,0-10,2.9-10,8.8"></path></g></svg><span class="self-center ml-2 text-sm">Made with MyST</span></a></div></div></div><main class="article-grid grid-gap"><article class="article-grid subgrid-gap col-screen article content"><div class="hidden"></div><div id="skip-to-frontmatter" aria-label="article frontmatter" class="mb-8 pt-9"><div class="flex items-center h-6 mb-5 text-sm font-light"><div class="flex-grow"></div></div><h1 class="mb-0">Accelerate DNN Training</h1><header class="mt-4 not-prose"><div class="grid grid-cols-1 sm:grid-cols-2 gap-y-1"><div><span class="font-semibold text-sm"><button class="focus:shadow-[0_0_0_2px] focus:shadow-black outline-none hover:underline" aria-label="Author Details" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R2t8top:" data-state="closed">Yao Lirong</button></span></div><div class="text-sm"><div>Cornell University<!-- --> </div></div></div></header><div class="flex mt-2 text-sm font-light"><time dateTime="2022-10-17" class="">October 17, 2022</time></div></div><div class="block my-10 lg:sticky lg:z-10 lg:h-0 lg:pt-0 lg:my-0 lg:ml-10 lg:col-margin-right" style="top:60px"><nav></nav></div><div id="skip-to-article"></div><h2 id="describing-capacity" class="relative group"><span class="heading-text">Describing Capacity</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#describing-capacity" title="Link to this Section" aria-label="Link to this Section">Â¶</a></h2><p><strong>Capacity</strong> of a model informally refers to the ability of the model to fit a wide range of possible functions.</p><ul><li>Models with high capacity tend to overfit.</li><li>Models with low capacity tend to underfit.</li></ul><p><strong>Representational Capacity</strong> of a model refers to the extent of functions this model can approximate well in theory. Deep neural networks have very high representational capacity. In fact, theyâ€™re universal approximators.</p><p><strong>Effective Capacity</strong> of a model refers to the extent of functions this model can approximate well in practice given a specific learning algorithm and dataset.</p><p>For convex optimization problem, a modelsâ€™ effective capacity is just the representational capacity since local minimum is a global minimum. But for nonconvex problems, a modelâ€™s effective capacity also depends on whether the dataset is representative or whether the learning algorithm is powerful. These two factors can have great effect on effective capacity, though have zero effect on representational capacity.</p><h2 id="early-stopping" class="relative group"><span class="heading-text">Early Stopping</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#early-stopping" title="Link to this Section" aria-label="Link to this Section">Â¶</a></h2><p>We stop the training when validation loss starts to get bigger.</p><ul><li><p><code>patience = K</code> - terminate training when validation loss has no improvement in the past K epochs</p></li><li><p><code>min_delta=0.01</code> - only an improvement greater than 0.01 is considered as an improvement. Anything lower than that is considered as no improvement.</p></li></ul><h2 id="dropout" class="relative group"><span class="heading-text">Dropout</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#dropout" title="Link to this Section" aria-label="Link to this Section">Â¶</a></h2><p>During training, randomly drop some neurons (force their activation value to 0) so they do not count as computation. For these neurons, we use 0 to back propagate their values.</p><p>In this way, we force all neurons to participate in training: imagine we have two neurons A and B. B always outputs a constant and itâ€™s A always changing to approximate all the values. Now we force A to output 0, B can no longer remain constant and it has to also participate in learning.</p><h2 id="batch-normalization" class="relative group"><span class="heading-text">Batch Normalization</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#batch-normalization" title="Link to this Section" aria-label="Link to this Section">Â¶</a></h2><p>To avoid great variance in the output of each neuron, we restrain the output of one neuron on a minibatch to have 0 mean and unit standard deviation.</p><p>Think of one specific neuron, let <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>u</mi><mo>=</mo><mo stretchy="false">[</mo><msub><mi>u</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>u</mi><mn>2</mn></msub><mo separator="true">,</mo><mo>â€¦</mo><mo separator="true">,</mo><msub><mi>u</mi><mi>B</mi></msub><mo stretchy="false">]</mo><mo>âˆˆ</mo><msup><mi mathvariant="double-struck">R</mi><mi>B</mi></msup></mrow><annotation encoding="application/x-tex">u = [u_1, u_2, \dots, u_B] \in \mathbb R^B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">u</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord"><span class="mord mathnormal">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner">â€¦</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05017em;">B</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">âˆˆ</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8413em;"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05017em;">B</span></span></span></span></span></span></span></span></span></span></span></span> be its output for all samples in this batch. Let</p><div id="BsbgDAGYHC" class="flex my-5 group"><div class="flex-grow overflow-x-auto overflow-y-hidden"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>B</mi><mi>N</mi><mo stretchy="false">(</mo><mi>u</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>u</mi><mo>âˆ’</mo><mi>Î¼</mi></mrow><mi>Ïƒ</mi></mfrac></mrow><annotation encoding="application/x-tex">BN(u) = \frac {u-\mu} {\sigma}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">BN</span><span class="mopen">(</span><span class="mord mathnormal">u</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.9463em;vertical-align:-0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.2603em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">Ïƒ</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">u</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">âˆ’</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal">Î¼</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></div><div class="relative self-center flex-none pl-2 m-0 text-right select-none"><a class="no-underline text-inherit hover:text-inherit text-inherit hover:text-inherit select-none hover:underline" href="#BsbgDAGYHC" title="Link to this Equation" aria-label="Link to this Equation">(<!-- -->1<!-- -->)</a></div></div><p>where <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Î¼</mi></mrow><annotation encoding="application/x-tex">\mu</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">Î¼</span></span></span></span></span> and <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Ïƒ</mi></mrow><annotation encoding="application/x-tex">\sigma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">Ïƒ</span></span></span></span></span> are the mean and standard deviation of <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>u</mi><mo>=</mo><mo stretchy="false">[</mo><msub><mi>u</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>u</mi><mn>2</mn></msub><mo separator="true">,</mo><mo>â€¦</mo><mo separator="true">,</mo><msub><mi>u</mi><mi>B</mi></msub><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">u = [u_1, u_2, \dots, u_B]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">u</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord"><span class="mord mathnormal">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner">â€¦</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05017em;">B</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">]</span></span></span></span></span>. After BN layer, it has 0 mean and unit sd.</p><p>This is how we calculate BN during training. In training, we also keep an <strong>exponential running average</strong> of <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Î¼</mi></mrow><annotation encoding="application/x-tex">\mu</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">Î¼</span></span></span></span></span> and <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>Ïƒ</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">\sigma^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">Ïƒ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span>, so <strong>during evaluation</strong>, we use these averages as the batch statistics. Batch Norm is usually <strong>applied before activation</strong>.</p><p>There are two problems with Batch Norm:</p><ol start="1"><li><p>We effectively reduced the representative capacity of our model by constraining mean to only be 0 and sd to only be 1. Note previously, each neuron can have different mean and sd, but now they all have the same.</p><p>We try to solve this problem by adding an affine term to assign a new non-zero mean <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Î²</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">Î²</span></span></span></span></span> and a new non-unit sd <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Î³</mi></mrow><annotation encoding="application/x-tex">\gamma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">Î³</span></span></span></span></span> to the activation value on this batch from this neuron. <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Î³</mi><mo separator="true">,</mo><mi>Î²</mi></mrow><annotation encoding="application/x-tex">\gamma, \beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">Î³</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">Î²</span></span></span></span></span> are two learnable terms here. (Note <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Î¼</mi><mo separator="true">,</mo><mi>Ïƒ</mi><mo separator="true">,</mo><mi>Î³</mi><mo separator="true">,</mo><mi>Î²</mi></mrow><annotation encoding="application/x-tex">\mu, \sigma, \gamma, \beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">Î¼</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">Ïƒ</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">Î³</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">Î²</span></span></span></span></span> are all scalars here)</p><div id="JkWuhIFJyz" class="flex my-5 group"><div class="flex-grow overflow-x-auto overflow-y-hidden"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>B</mi><mi>N</mi><mo stretchy="false">(</mo><mi>u</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>u</mi><mo>âˆ’</mo><mi>Î¼</mi></mrow><mi>Ïƒ</mi></mfrac><mi>Î³</mi><mo>+</mo><mi>Î²</mi></mrow><annotation encoding="application/x-tex">BN(u) = \frac {u-\mu} {\sigma} \gamma + \beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">BN</span><span class="mopen">(</span><span class="mord mathnormal">u</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.9463em;vertical-align:-0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.2603em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">Ïƒ</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">u</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">âˆ’</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal">Î¼</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord mathnormal" style="margin-right:0.05556em;">Î³</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">Î²</span></span></span></span></span></div><div class="relative self-center flex-none pl-2 m-0 text-right select-none"><a class="no-underline text-inherit hover:text-inherit text-inherit hover:text-inherit select-none hover:underline" href="#JkWuhIFJyz" title="Link to this Equation" aria-label="Link to this Equation">(<!-- -->2<!-- -->)</a></div></div><p>However, doesnâ€™t this defeat the purpose of normalizing in the first place? This considered, the above equation is still the common practice though we donâ€™t know why it works</p></li><li><p>All previous proofs depend on the fact that calculation of gradient step on each sample in minibatch is independent. However, by adding the mean <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Î¼</mi></mrow><annotation encoding="application/x-tex">\mu</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">Î¼</span></span></span></span></span> and sd <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Ïƒ</mi></mrow><annotation encoding="application/x-tex">\sigma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">Ïƒ</span></span></span></span></span>, we make the update step dependent of each other, since mean and sd depend on all samples. This nullifies all the proofs we did previously ensuring good properties of SGD. Despite this, it performs good and people use it.</p></li></ol><h2 id="residual-block-skip-connection" class="relative group"><span class="heading-text">Residual Block / Skip Connection</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#residual-block-skip-connection" title="Link to this Section" aria-label="Link to this Section">Â¶</a></h2><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-text" style="white-space:pre">L0 ---- L1 ---- sigma1 ---- L2 ---- sigma2 --+--
     |                                       |
     -----------------------------------------</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><p>The L here are some computation layers and sigma is the non-linear activation layer.</p><p>So why do we add this skip connection? Imagine L2 does something weird that prevent learning (maybe all its weights go to 0, so gradient of this point to earlier layers all go to 0 when we compute it in back propagation). By adding L0 value, we ensure that even if L2 doesnâ€™t work, the whole network can still work (for this particular example, we can then make L0 gradient non-zero even whatâ€™s in between all have gradient 0)</p><p>The classic ResNet employs this architecture:</p><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-text" style="white-space:pre">L0 ---- conv1 ---- BN1 ---- sigma1 ---- conv2 ---- BN2 --+-- sigma2
     |                                                   |
     -----------------------------------------------------</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># https://github.com/akamaster/pytorch_resnet_cifar10/blob/master/resnet.py/ class BasicBlock
def forward(self, x):
    out = F.relu(self.bn1(self.conv1(x)))
    out = self.bn2(self.conv2(out))
    out += self.shortcut(x)
    out = F.relu(out)
    return out</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><p>People donâ€™t usually relate this to RNN because an RNN takes in sequence of inputs and each token of it is passed into the same weight / model.</p><div></div><div class="flex pt-10 mb-10 space-x-4"><a class="flex-1 block p-4 font-normal text-gray-600 no-underline border border-gray-200 rounded shadow-sm group hover:border-blue-600 dark:hover:border-blue-400 hover:text-blue-600 dark:hover:text-blue-400 dark:text-gray-100 dark:border-gray-500 hover:shadow-lg dark:shadow-neutral-700" href="/cornell-notes/2022-10-12-neural-network-review"><div class="flex h-full align-middle"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="self-center transition-transform group-hover:-translate-x-1 shrink-0"><path stroke-linecap="round" stroke-linejoin="round" d="M10.5 19.5 3 12m0 0 7.5-7.5M3 12h18"></path></svg><div class="flex-grow text-right"><div class="text-xs text-gray-500 dark:text-gray-400">CS4787 Principles of Large-Scale Machine Learning</div>Neural Network Review</div></div></a><a class="flex-1 block p-4 font-normal text-gray-600 no-underline border border-gray-200 rounded shadow-sm group hover:border-blue-600 dark:hover:border-blue-400 hover:text-blue-600 dark:hover:text-blue-400 dark:text-gray-100 dark:border-gray-500 hover:shadow-lg dark:shadow-neutral-700" href="/cornell-notes/2022-10-19-beyond-supervised-learning"><div class="flex h-full align-middle"><div class="flex-grow"><div class="text-xs text-gray-500 dark:text-gray-400">CS4787 Principles of Large-Scale Machine Learning</div>Beyond supervised learning</div><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="self-center transition-transform group-hover:translate-x-1 shrink-0"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 4.5 21 12m0 0-7.5 7.5M21 12H3"></path></svg></div></a></div></article></main><script>((a,d)=>{if(!window.history.state||!window.history.state.key){let h=Math.random().toString(32).slice(2);window.history.replaceState({key:h},"")}try{let f=JSON.parse(sessionStorage.getItem(a)||"{}")[d||window.history.state.key];typeof f=="number"&&window.scrollTo(0,f)}catch(h){console.error(h),sessionStorage.removeItem(a)}})("positions", null)</script><link rel="modulepreload" href="/cornell-notes/build/entry.client-UNPC4GT3.js"/><link rel="modulepreload" href="/cornell-notes/build/_shared/chunk-OCTKKCIL.js"/><link rel="modulepreload" href="/cornell-notes/build/_shared/chunk-UAI5KRM7.js"/><link rel="modulepreload" href="/cornell-notes/build/_shared/chunk-2NH4LW52.js"/><link rel="modulepreload" href="/cornell-notes/build/_shared/chunk-L6RR67CB.js"/><link rel="modulepreload" href="/cornell-notes/build/_shared/chunk-HBJK6BW3.js"/><link rel="modulepreload" href="/cornell-notes/build/_shared/chunk-HYMQ7M2K.js"/><link rel="modulepreload" href="/cornell-notes/build/_shared/chunk-OHOXABTA.js"/><link rel="modulepreload" href="/cornell-notes/build/_shared/chunk-OCWQY3HK.js"/><link rel="modulepreload" href="/cornell-notes/build/_shared/chunk-C7FW3E47.js"/><link rel="modulepreload" href="/cornell-notes/build/_shared/chunk-3CVK3PYF.js"/><link rel="modulepreload" href="/cornell-notes/build/_shared/chunk-J6FHCSRC.js"/><link rel="modulepreload" href="/cornell-notes/build/_shared/chunk-ND43KHSX.js"/><link rel="modulepreload" href="/cornell-notes/build/_shared/chunk-GUCIBHGO.js"/><link rel="modulepreload" href="/cornell-notes/build/root-LY5YATWI.js"/><link rel="modulepreload" href="/cornell-notes/build/_shared/chunk-KBQ63U4V.js"/><link rel="modulepreload" href="/cornell-notes/build/routes/$-RAODST7L.js"/><script>window.__remixContext = {"url":"/2022-10-17-accelerate-dnn-training","state":{"loaderData":{"root":{"config":{"version":2,"myst":"1.6.0","options":{"favicon":"/cornell-notes/build/favicon-615119cb910b2b2604fa7c8e61a4cffe.ico","logo":"/cornell-notes/build/cornhell-37b881e150badb60bb90a0054b1665ba.png"},"nav":[],"actions":[],"projects":[{"title":"Incomplete CS Notes @ Cornell","description":"This is a complete collection of course notes I've taken when studying CS at Cornell University","authors":[{"nameParsed":{"literal":"Yao Lirong","given":"Yao","family":"Lirong"},"name":"Yao Lirong","affiliations":["Cornell University"],"url":"https://yao-lirong.github.io","linkedin":"https://www.linkedin.com/in/yao-lirong/","id":"contributors-myst-generated-uid-0"}],"keywords":["Cornell","CS","Yao Lirong"],"affiliations":[{"id":"Cornell University","name":"Cornell University"}],"id":"dbd3e509-63c9-4982-a7c3-5cf505dc3c02","toc":[{"file":"index.md"},{"file":"2020-10-02-INFO1998-Intro-to-Machine-Learning.md"},{"file":"2020-09-07-CS2024-C++-Programming.md"},{"children":[{"file":"CS2112/2019-09-24-Generics.md"},{"file":"CS2112/2019-09-30-Value-Representation,-Hashing,-and-Generics.md"},{"file":"CS2112/2019-10-08-Parsing.md"},{"file":"CS2112/2019-10-17-Designing-and-documenting-interfaces-and-implementations.md"},{"file":"CS2112/2019-10-24-Design-Pattern.md"},{"file":"CS2112/2019-10-29 Event Handlers.md"},{"file":"CS2112/2019-11-07-Concurrency.md"},{"file":"CS2112/2019-11-12-synchronization.md"},{"file":"CS2112/2019-11-19-Graph-Traversal.md"},{"file":"CS2112/2019-11-20-Graph-(Recitation).md"},{"file":"CS2112/2019-11-21-shortest-path-algorithm.md"},{"file":"CS2112/2019-11-23-Android-Basics-User-Interface.md"},{"file":"CS2112/2019-11-26-Priority-Queue-and-Heap.md"},{"file":"CS2112/2019-12-05-Problem-Analysis.md"}],"title":"CS2112 Object-Oriented Design (Honors)"},{"children":[{"file":"CS3110/2020-01-28-Functions.md"},{"file":"CS3110/2020-01-30-Standard-Data-Types.md"},{"file":"CS3110/2020-02-04-Advanced-Data-Types.md"},{"file":"CS3110/2020-02-06-Higher-Order-Functions.md"},{"file":"CS3110/2020-02-11-Modules.md"},{"file":"CS3110/2020-02-13-Code-Reuse-with-Modules.md"},{"file":"CS3110/2020-02-18-Specifications.md"},{"file":"CS3110/2020-03-03-Mutability.md"},{"file":"CS3110/2020-04-06-Red-Black-Tree.md"},{"file":"CS3110/2020-04-09-Interpreter.md"},{"file":"CS3110/2020-04-14-The-Substitution-Model.md"},{"file":"CS3110/2020-04-16-The-Environment-Model.md"}],"title":"CS3110 Functional Programming"},{"children":[{"file":"CS4780/2021-08-31-Machine-Learning-Basics.md"},{"file":"CS4780/2021-09-02-K-Nearest-Neighbors.md"},{"file":"CS4780/2021-09-07-K-means-clustering.md"},{"file":"CS4780/2021-09-09-Principal-Component-Analysis.md"},{"file":"CS4780/2021-09-14-The-Perceptron.md"},{"file":"CS4780/2021-09-16-MLE-and-MAP.md"},{"file":"CS4780/2021-09-21-Naive-Bayes.md"},{"file":"CS4780/2021-09-28-Logistic-Regression.md"},{"file":"CS4780/2021-09-30-Gradient-Descent.md"},{"file":"CS4780/2021-10-05-Important-Distributions-and-Linear-Regression.md"},{"file":"CS4780/2021-10-07-SVM---Support-Vector-Machine.md"},{"file":"CS4780/2021-10-14-Empirical-Risk-Minimization.md"},{"file":"CS4780/2021-10-19-Midterm-Review.md"},{"file":"CS4780/2021-10-26-Bias-Variance-Tradeoff.md"},{"file":"CS4780/2021-10-28-Model-Selection-Tricks.md"},{"file":"CS4780/2021-11-02-Kernels.md"},{"file":"CS4780/2021-11-04-More-on-Kernels.md"},{"file":"CS4780/2021-11-09-Decision-Tree.md"},{"file":"CS4780/2021-11-16-Bagging.md"},{"file":"CS4780/2021-11-18-Boosting.md"}],"title":"CS4780 Intro to Machine Learning"},{"children":[{"file":"CS4787/2022-08-22-Introduction.md"},{"file":"CS4787/2022-08-24-Linear-Algebra-and-NumPy.md"},{"file":"CS4787/2022-08-29-Automatic-Differentiation.md"},{"file":"CS4787/2022-08-31-Back-Propagation.md"},{"file":"CS4787/2022-09-12-Gradient-Descent.md"},{"file":"CS4787/2022-09-14-Gradient-Descent-and-Convexity.md"},{"file":"CS4787/2022-09-19-Stochastic-Gradient-Descent.md"},{"file":"CS4787/2022-09-21-Stochastic-Gradient-Descent-Improved.md"},{"file":"CS4787/2022-09-26-SGD-with-Momentum.md"},{"file":"CS4787/2022-09-28-Preconditioning-and-Element-Specific-Learning-Rate.md"},{"file":"CS4787/2022-10-03-Adaptive-Learning-Rate-and-Variance-Reduction.md"},{"file":"CS4787/2022-10-05-Sparsity-and-Dimension-Reduction.md"},{"file":"CS4787/2022-10-12-Neural-Network-Review.md"},{"file":"CS4787/2022-10-17-Accelerate-DNN-Training.md"},{"file":"CS4787/2022-10-19-Beyond-supervised-learning.md"},{"file":"CS4787/2022-10-24-Attention,-Transformers,-and-Transfer-Learning.md"}],"title":"CS4787 Principles of Large-Scale Machine Learning"},{"file":"2020-10-13-CS4820-Intro-to-Analysis-of-Algorithms.md"},{"file":"2022-02-08-ORIE4350-Game-Theory.md"}],"thumbnail":"/cornell-notes/build/cornhell-37b881e150badb60bb90a0054b1665ba.png","exports":[],"bibliography":[],"index":"index","pages":[{"slug":"2020-10-02-info1998-intro-to-machine-learning","title":"INFO1998 Intro to Machine Learning","description":"","date":"2020-10-02","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20FA","Python"],"level":1},{"slug":"2020-09-07-cs2024-c-programming","title":"CS2024 C++ Programming","description":"","date":"2020-09-07","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","CS2024","20FA"],"level":1},{"level":1,"title":"CS2112 Object-Oriented Design (Honors)"},{"slug":"2019-09-24-generics","title":"Generics","description":"","date":"2019-09-24","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","19FA","CS2112"],"level":2},{"slug":"2019-09-30-value-representation-hashing-and-generi","title":"Value Representation, Hashing, and Generics","description":"","date":"2019-09-30","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","FA19","CS2112"],"level":2},{"slug":"2019-10-08-parsing","title":"Parsing","description":"","date":"2019-10-08","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","19FA","CS2112"],"level":2},{"slug":"2019-10-17-designing-and-documenting-interfaces-an","title":"Designing and documenting interfaces and implementations","description":"","date":"2019-10-17","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","19FA","CS2112"],"level":2},{"slug":"2019-10-24-design-pattern","title":"Design Pattern","description":"","date":"2019-10-24","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","19FA","CS2112"],"level":2},{"slug":"2019-10-29-event-handlers","title":"Building GUI","description":"","date":"2019-10-29","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","19FA","CS2112"],"level":2},{"slug":"2019-11-07-concurrency","title":"Concurrency","description":"","date":"2019-11-07","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","19FA","CS2112"],"level":2},{"slug":"2019-11-12-synchronization","title":"Synchronization","description":"","date":"2019-11-12","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","19FA","CS2112"],"level":2},{"slug":"2019-11-19-graph-traversal","title":"Graph Traversal","description":"","date":"2019-11-19","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","19FA","CS2112"],"level":2},{"slug":"2019-11-20-graph-recitation","title":"Graph (Recitation)","description":"","date":"2019-11-20","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","19FA","CS2112"],"level":2},{"slug":"2019-11-21-shortest-path-algorithm","title":"shortest path algorithm","description":"","date":"2019-11-21","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","CS2112"],"level":2},{"slug":"2019-11-23-android-basics-user-interface","title":"Udacity: Android Basics","description":"","date":"2019-11-23","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Android"],"level":2},{"slug":"2019-11-26-priority-queue-and-heap","title":"Priority Queue and Heap","description":"","date":"2019-11-26","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","CS2112"],"level":2},{"slug":"2019-12-05-problem-analysis","title":"Problem Analysis","description":"","date":"2019-12-05","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","CS2112"],"level":2},{"level":1,"title":"CS3110 Functional Programming"},{"slug":"2020-01-28-functions","title":"Functions","description":"","date":"2020-01-28","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"slug":"2020-01-30-standard-data-types","title":"Standard Data Types","description":"","date":"2020-01-30","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"slug":"2020-02-04-advanced-data-types","title":"Advanced Data Types","description":"","date":"2020-02-04","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"slug":"2020-02-06-higher-order-functions","title":"Higher-Order Functions","description":"","date":"2020-02-06","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"slug":"2020-02-11-modules","title":"Modules","description":"","date":"2020-02-11","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"slug":"2020-02-13-code-reuse-with-modules","title":"Code Reuse with Modules","description":"","date":"2020-02-13","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"slug":"2020-02-18-specifications","title":"Specifications","description":"","date":"2020-02-18","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"slug":"2020-03-03-mutability","title":"Mutability","description":"","date":"2020-03-03","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"slug":"2020-04-06-red-black-tree","title":"Red Black Tree","description":"","date":"2020-04-06","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","CS3110","20SP"],"level":2},{"slug":"2020-04-09-interpreter","title":"Interpreter","description":"","date":"2020-04-09","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"slug":"2020-04-14-the-substitution-model","title":"The Substitution Model","description":"","date":"2020-04-14","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"slug":"2020-04-16-the-environment-model","title":"The Environment Model","description":"","date":"2020-04-16","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"level":1,"title":"CS4780 Intro to Machine Learning"},{"slug":"2021-08-31-machine-learning-basics","title":"Machine Learning Basics","description":"","date":"2021-08-31","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS"],"level":2},{"slug":"2021-09-02-k-nearest-neighbors","title":"K-Nearest Neighbors","description":"","date":"2021-09-02","thumbnail":"/cornell-notes/build/d2d32ed7f030408c4751b4082cc4c4fb.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-09-07-k-means-clustering","title":"K-means clustering","description":"","date":"2021-09-07","thumbnail":"/cornell-notes/build/2b624c0dfc4541e6702d7d03a35846a3.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-09-09-principal-component-analysis","title":"Principal Component Analysis","description":"","date":"2021-09-09","thumbnail":"/cornell-notes/build/0f82a0d8a1b909f3be9ff331e1e605e3.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-09-14-the-perceptron","title":"The Perceptron","description":"","date":"2021-09-14","thumbnail":"/cornell-notes/build/0561dbd9a0937d3d1decc2a2e9d7a150.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-09-16-mle-and-map","title":"MLE and MAP","description":"","date":"2021-09-16","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-09-21-naive-bayes","title":"Naive Bayes","description":"","date":"2021-09-21","thumbnail":"/cornell-notes/build/1dec3195698f490f89eb8383ef29b8c8.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-09-28-logistic-regression","title":"Logistic Regression","description":"","date":"2021-09-28","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-09-30-gradient-descent","title":"Gradient Descent","description":"","date":"2021-09-30","thumbnail":"/cornell-notes/build/e3d52da6368f919deb4783b786520acd.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-10-05-important-distributions-and-linear-regr","title":"Important Distributions and Linear Regression","description":"","date":"2021-10-05","thumbnail":"/cornell-notes/build/023faa064932bbe5ec11298e7cbdbdbd.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-10-07-svm-support-vector-machine","title":"SVM - Support Vector Machine","description":"","date":"2021-10-07","thumbnail":"/cornell-notes/build/41379864e80001dd60125813623c4915.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-10-14-empirical-risk-minimization","title":"Empirical Risk Minimization","description":"","date":"2021-10-14","thumbnail":"/cornell-notes/build/f9e37f639bf7ed7d0e0daf5d55dee992.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-10-19-midterm-review","title":"Midterm Review","description":"","date":"2021-10-19","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-10-26-bias-variance-tradeoff","title":"Bias-Variance Tradeoff","description":"","date":"2021-10-26","thumbnail":"/cornell-notes/build/92f79954ba3e60170a726689263cc46c.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-10-28-model-selection-tricks","title":"Model Selection Tricks","description":"","date":"2021-10-28","thumbnail":"/cornell-notes/build/643c4fcd86a736a95208145a3a53f8ee.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-11-02-kernels","title":"Kernels","description":"","date":"2021-11-02","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-11-04-more-on-kernels","title":"More on Kernels","description":"","date":"2021-11-04","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-11-09-decision-tree","title":"Decision Tree","description":"","date":"2021-11-09","thumbnail":"/cornell-notes/build/2f6b3cd8046659d873cef1793b421adf.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-11-16-bagging","title":"Bagging","description":"","date":"2021-11-16","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-11-18-boosting","title":"Boosting","description":"","date":"2021-11-18","thumbnail":"/cornell-notes/build/315b0684d85fc252232fdf8cba2a9c87.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"CS4787 Principles of Large-Scale Machine Learning"},{"slug":"2022-08-22-introduction","title":"Introduction","description":"","date":"2022-08-22","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-08-24-linear-algebra-and-numpy","title":"Linear Algebra and NumPy","description":"","date":"2022-08-24","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-08-29-automatic-differentiation","title":"Automatic Differentiation","description":"","date":"2022-08-29","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-08-31-back-propagation","title":"Back Propagation","description":"","date":"2022-08-31","thumbnail":"/cornell-notes/build/9a793e5d3b94eacefaeb4ada8b427898.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-09-12-gradient-descent","title":"Gradient Descent","description":"","date":"2022-09-12","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-09-14-gradient-descent-and-convexity","title":"Gradient Descent and Convexity","description":"","date":"2022-09-14","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-09-19-stochastic-gradient-descent","title":"Stochastic Gradient Descent","description":"","date":"2022-09-19","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-09-21-stochastic-gradient-descent-improved","title":"Stochastic Gradient Descent Improved","description":"","date":"2022-09-21","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-09-26-sgd-with-momentum","title":"SGD with Momentum","description":"","date":"2022-09-26","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-09-28-preconditioning-and-element-specific-le","title":"Preconditioning and Element Specific Learning Rate","description":"","date":"2022-09-28","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-10-03-adaptive-learning-rate-and-variance-red","title":"Adaptive Learning Rate and Variance Reduction","description":"","date":"2022-10-03","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-10-05-sparsity-and-dimension-reduction","title":"Sparsity and Dimension Reduction","description":"","date":"2022-10-05","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-10-12-neural-network-review","title":"Neural Network Review","description":"","date":"2022-10-12","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-10-17-accelerate-dnn-training","title":"Accelerate DNN Training","description":"","date":"2022-10-17","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-10-19-beyond-supervised-learning","title":"Beyond supervised learning","description":"","date":"2022-10-19","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-10-24-attention-transformers-and-transfer-lea","title":"Attention, Transformers, and Transfer Learning","description":"","date":"2022-10-24","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2020-10-13-cs4820-intro-to-analysis-of-algorithms","title":"CS4820 Intro to Analysis of Algorithms","description":"","date":"2020-10-13","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","CS4820"],"level":1},{"slug":"2022-02-08-orie4350-game-theory","title":"ORIE4350 Game Theory","description":"","date":"2022-02-08","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1}]}]},"CONTENT_CDN_PORT":"3100","MODE":"static","BASE_URL":"/cornell-notes"},"routes/$":{"config":{"version":2,"myst":"1.6.0","options":{"favicon":"/cornell-notes/build/favicon-615119cb910b2b2604fa7c8e61a4cffe.ico","logo":"/cornell-notes/build/cornhell-37b881e150badb60bb90a0054b1665ba.png"},"nav":[],"actions":[],"projects":[{"title":"Incomplete CS Notes @ Cornell","description":"This is a complete collection of course notes I've taken when studying CS at Cornell University","authors":[{"nameParsed":{"literal":"Yao Lirong","given":"Yao","family":"Lirong"},"name":"Yao Lirong","affiliations":["Cornell University"],"url":"https://yao-lirong.github.io","linkedin":"https://www.linkedin.com/in/yao-lirong/","id":"contributors-myst-generated-uid-0"}],"keywords":["Cornell","CS","Yao Lirong"],"affiliations":[{"id":"Cornell University","name":"Cornell University"}],"id":"dbd3e509-63c9-4982-a7c3-5cf505dc3c02","toc":[{"file":"index.md"},{"file":"2020-10-02-INFO1998-Intro-to-Machine-Learning.md"},{"file":"2020-09-07-CS2024-C++-Programming.md"},{"children":[{"file":"CS2112/2019-09-24-Generics.md"},{"file":"CS2112/2019-09-30-Value-Representation,-Hashing,-and-Generics.md"},{"file":"CS2112/2019-10-08-Parsing.md"},{"file":"CS2112/2019-10-17-Designing-and-documenting-interfaces-and-implementations.md"},{"file":"CS2112/2019-10-24-Design-Pattern.md"},{"file":"CS2112/2019-10-29 Event Handlers.md"},{"file":"CS2112/2019-11-07-Concurrency.md"},{"file":"CS2112/2019-11-12-synchronization.md"},{"file":"CS2112/2019-11-19-Graph-Traversal.md"},{"file":"CS2112/2019-11-20-Graph-(Recitation).md"},{"file":"CS2112/2019-11-21-shortest-path-algorithm.md"},{"file":"CS2112/2019-11-23-Android-Basics-User-Interface.md"},{"file":"CS2112/2019-11-26-Priority-Queue-and-Heap.md"},{"file":"CS2112/2019-12-05-Problem-Analysis.md"}],"title":"CS2112 Object-Oriented Design (Honors)"},{"children":[{"file":"CS3110/2020-01-28-Functions.md"},{"file":"CS3110/2020-01-30-Standard-Data-Types.md"},{"file":"CS3110/2020-02-04-Advanced-Data-Types.md"},{"file":"CS3110/2020-02-06-Higher-Order-Functions.md"},{"file":"CS3110/2020-02-11-Modules.md"},{"file":"CS3110/2020-02-13-Code-Reuse-with-Modules.md"},{"file":"CS3110/2020-02-18-Specifications.md"},{"file":"CS3110/2020-03-03-Mutability.md"},{"file":"CS3110/2020-04-06-Red-Black-Tree.md"},{"file":"CS3110/2020-04-09-Interpreter.md"},{"file":"CS3110/2020-04-14-The-Substitution-Model.md"},{"file":"CS3110/2020-04-16-The-Environment-Model.md"}],"title":"CS3110 Functional Programming"},{"children":[{"file":"CS4780/2021-08-31-Machine-Learning-Basics.md"},{"file":"CS4780/2021-09-02-K-Nearest-Neighbors.md"},{"file":"CS4780/2021-09-07-K-means-clustering.md"},{"file":"CS4780/2021-09-09-Principal-Component-Analysis.md"},{"file":"CS4780/2021-09-14-The-Perceptron.md"},{"file":"CS4780/2021-09-16-MLE-and-MAP.md"},{"file":"CS4780/2021-09-21-Naive-Bayes.md"},{"file":"CS4780/2021-09-28-Logistic-Regression.md"},{"file":"CS4780/2021-09-30-Gradient-Descent.md"},{"file":"CS4780/2021-10-05-Important-Distributions-and-Linear-Regression.md"},{"file":"CS4780/2021-10-07-SVM---Support-Vector-Machine.md"},{"file":"CS4780/2021-10-14-Empirical-Risk-Minimization.md"},{"file":"CS4780/2021-10-19-Midterm-Review.md"},{"file":"CS4780/2021-10-26-Bias-Variance-Tradeoff.md"},{"file":"CS4780/2021-10-28-Model-Selection-Tricks.md"},{"file":"CS4780/2021-11-02-Kernels.md"},{"file":"CS4780/2021-11-04-More-on-Kernels.md"},{"file":"CS4780/2021-11-09-Decision-Tree.md"},{"file":"CS4780/2021-11-16-Bagging.md"},{"file":"CS4780/2021-11-18-Boosting.md"}],"title":"CS4780 Intro to Machine Learning"},{"children":[{"file":"CS4787/2022-08-22-Introduction.md"},{"file":"CS4787/2022-08-24-Linear-Algebra-and-NumPy.md"},{"file":"CS4787/2022-08-29-Automatic-Differentiation.md"},{"file":"CS4787/2022-08-31-Back-Propagation.md"},{"file":"CS4787/2022-09-12-Gradient-Descent.md"},{"file":"CS4787/2022-09-14-Gradient-Descent-and-Convexity.md"},{"file":"CS4787/2022-09-19-Stochastic-Gradient-Descent.md"},{"file":"CS4787/2022-09-21-Stochastic-Gradient-Descent-Improved.md"},{"file":"CS4787/2022-09-26-SGD-with-Momentum.md"},{"file":"CS4787/2022-09-28-Preconditioning-and-Element-Specific-Learning-Rate.md"},{"file":"CS4787/2022-10-03-Adaptive-Learning-Rate-and-Variance-Reduction.md"},{"file":"CS4787/2022-10-05-Sparsity-and-Dimension-Reduction.md"},{"file":"CS4787/2022-10-12-Neural-Network-Review.md"},{"file":"CS4787/2022-10-17-Accelerate-DNN-Training.md"},{"file":"CS4787/2022-10-19-Beyond-supervised-learning.md"},{"file":"CS4787/2022-10-24-Attention,-Transformers,-and-Transfer-Learning.md"}],"title":"CS4787 Principles of Large-Scale Machine Learning"},{"file":"2020-10-13-CS4820-Intro-to-Analysis-of-Algorithms.md"},{"file":"2022-02-08-ORIE4350-Game-Theory.md"}],"thumbnail":"/cornell-notes/build/cornhell-37b881e150badb60bb90a0054b1665ba.png","exports":[],"bibliography":[],"index":"index","pages":[{"slug":"2020-10-02-info1998-intro-to-machine-learning","title":"INFO1998 Intro to Machine Learning","description":"","date":"2020-10-02","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20FA","Python"],"level":1},{"slug":"2020-09-07-cs2024-c-programming","title":"CS2024 C++ Programming","description":"","date":"2020-09-07","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","CS2024","20FA"],"level":1},{"level":1,"title":"CS2112 Object-Oriented Design (Honors)"},{"slug":"2019-09-24-generics","title":"Generics","description":"","date":"2019-09-24","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","19FA","CS2112"],"level":2},{"slug":"2019-09-30-value-representation-hashing-and-generi","title":"Value Representation, Hashing, and Generics","description":"","date":"2019-09-30","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","FA19","CS2112"],"level":2},{"slug":"2019-10-08-parsing","title":"Parsing","description":"","date":"2019-10-08","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","19FA","CS2112"],"level":2},{"slug":"2019-10-17-designing-and-documenting-interfaces-an","title":"Designing and documenting interfaces and implementations","description":"","date":"2019-10-17","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","19FA","CS2112"],"level":2},{"slug":"2019-10-24-design-pattern","title":"Design Pattern","description":"","date":"2019-10-24","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","19FA","CS2112"],"level":2},{"slug":"2019-10-29-event-handlers","title":"Building GUI","description":"","date":"2019-10-29","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","19FA","CS2112"],"level":2},{"slug":"2019-11-07-concurrency","title":"Concurrency","description":"","date":"2019-11-07","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","19FA","CS2112"],"level":2},{"slug":"2019-11-12-synchronization","title":"Synchronization","description":"","date":"2019-11-12","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","19FA","CS2112"],"level":2},{"slug":"2019-11-19-graph-traversal","title":"Graph Traversal","description":"","date":"2019-11-19","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","19FA","CS2112"],"level":2},{"slug":"2019-11-20-graph-recitation","title":"Graph (Recitation)","description":"","date":"2019-11-20","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","19FA","CS2112"],"level":2},{"slug":"2019-11-21-shortest-path-algorithm","title":"shortest path algorithm","description":"","date":"2019-11-21","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","CS2112"],"level":2},{"slug":"2019-11-23-android-basics-user-interface","title":"Udacity: Android Basics","description":"","date":"2019-11-23","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Android"],"level":2},{"slug":"2019-11-26-priority-queue-and-heap","title":"Priority Queue and Heap","description":"","date":"2019-11-26","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","CS2112"],"level":2},{"slug":"2019-12-05-problem-analysis","title":"Problem Analysis","description":"","date":"2019-12-05","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","CS2112"],"level":2},{"level":1,"title":"CS3110 Functional Programming"},{"slug":"2020-01-28-functions","title":"Functions","description":"","date":"2020-01-28","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"slug":"2020-01-30-standard-data-types","title":"Standard Data Types","description":"","date":"2020-01-30","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"slug":"2020-02-04-advanced-data-types","title":"Advanced Data Types","description":"","date":"2020-02-04","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"slug":"2020-02-06-higher-order-functions","title":"Higher-Order Functions","description":"","date":"2020-02-06","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"slug":"2020-02-11-modules","title":"Modules","description":"","date":"2020-02-11","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"slug":"2020-02-13-code-reuse-with-modules","title":"Code Reuse with Modules","description":"","date":"2020-02-13","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"slug":"2020-02-18-specifications","title":"Specifications","description":"","date":"2020-02-18","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"slug":"2020-03-03-mutability","title":"Mutability","description":"","date":"2020-03-03","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"slug":"2020-04-06-red-black-tree","title":"Red Black Tree","description":"","date":"2020-04-06","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","CS3110","20SP"],"level":2},{"slug":"2020-04-09-interpreter","title":"Interpreter","description":"","date":"2020-04-09","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"slug":"2020-04-14-the-substitution-model","title":"The Substitution Model","description":"","date":"2020-04-14","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"slug":"2020-04-16-the-environment-model","title":"The Environment Model","description":"","date":"2020-04-16","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"level":1,"title":"CS4780 Intro to Machine Learning"},{"slug":"2021-08-31-machine-learning-basics","title":"Machine Learning Basics","description":"","date":"2021-08-31","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS"],"level":2},{"slug":"2021-09-02-k-nearest-neighbors","title":"K-Nearest Neighbors","description":"","date":"2021-09-02","thumbnail":"/cornell-notes/build/d2d32ed7f030408c4751b4082cc4c4fb.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-09-07-k-means-clustering","title":"K-means clustering","description":"","date":"2021-09-07","thumbnail":"/cornell-notes/build/2b624c0dfc4541e6702d7d03a35846a3.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-09-09-principal-component-analysis","title":"Principal Component Analysis","description":"","date":"2021-09-09","thumbnail":"/cornell-notes/build/0f82a0d8a1b909f3be9ff331e1e605e3.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-09-14-the-perceptron","title":"The Perceptron","description":"","date":"2021-09-14","thumbnail":"/cornell-notes/build/0561dbd9a0937d3d1decc2a2e9d7a150.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-09-16-mle-and-map","title":"MLE and MAP","description":"","date":"2021-09-16","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-09-21-naive-bayes","title":"Naive Bayes","description":"","date":"2021-09-21","thumbnail":"/cornell-notes/build/1dec3195698f490f89eb8383ef29b8c8.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-09-28-logistic-regression","title":"Logistic Regression","description":"","date":"2021-09-28","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-09-30-gradient-descent","title":"Gradient Descent","description":"","date":"2021-09-30","thumbnail":"/cornell-notes/build/e3d52da6368f919deb4783b786520acd.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-10-05-important-distributions-and-linear-regr","title":"Important Distributions and Linear Regression","description":"","date":"2021-10-05","thumbnail":"/cornell-notes/build/023faa064932bbe5ec11298e7cbdbdbd.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-10-07-svm-support-vector-machine","title":"SVM - Support Vector Machine","description":"","date":"2021-10-07","thumbnail":"/cornell-notes/build/41379864e80001dd60125813623c4915.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-10-14-empirical-risk-minimization","title":"Empirical Risk Minimization","description":"","date":"2021-10-14","thumbnail":"/cornell-notes/build/f9e37f639bf7ed7d0e0daf5d55dee992.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-10-19-midterm-review","title":"Midterm Review","description":"","date":"2021-10-19","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-10-26-bias-variance-tradeoff","title":"Bias-Variance Tradeoff","description":"","date":"2021-10-26","thumbnail":"/cornell-notes/build/92f79954ba3e60170a726689263cc46c.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-10-28-model-selection-tricks","title":"Model Selection Tricks","description":"","date":"2021-10-28","thumbnail":"/cornell-notes/build/643c4fcd86a736a95208145a3a53f8ee.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-11-02-kernels","title":"Kernels","description":"","date":"2021-11-02","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-11-04-more-on-kernels","title":"More on Kernels","description":"","date":"2021-11-04","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-11-09-decision-tree","title":"Decision Tree","description":"","date":"2021-11-09","thumbnail":"/cornell-notes/build/2f6b3cd8046659d873cef1793b421adf.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-11-16-bagging","title":"Bagging","description":"","date":"2021-11-16","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-11-18-boosting","title":"Boosting","description":"","date":"2021-11-18","thumbnail":"/cornell-notes/build/315b0684d85fc252232fdf8cba2a9c87.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"CS4787 Principles of Large-Scale Machine Learning"},{"slug":"2022-08-22-introduction","title":"Introduction","description":"","date":"2022-08-22","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-08-24-linear-algebra-and-numpy","title":"Linear Algebra and NumPy","description":"","date":"2022-08-24","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-08-29-automatic-differentiation","title":"Automatic Differentiation","description":"","date":"2022-08-29","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-08-31-back-propagation","title":"Back Propagation","description":"","date":"2022-08-31","thumbnail":"/cornell-notes/build/9a793e5d3b94eacefaeb4ada8b427898.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-09-12-gradient-descent","title":"Gradient Descent","description":"","date":"2022-09-12","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-09-14-gradient-descent-and-convexity","title":"Gradient Descent and Convexity","description":"","date":"2022-09-14","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-09-19-stochastic-gradient-descent","title":"Stochastic Gradient Descent","description":"","date":"2022-09-19","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-09-21-stochastic-gradient-descent-improved","title":"Stochastic Gradient Descent Improved","description":"","date":"2022-09-21","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-09-26-sgd-with-momentum","title":"SGD with Momentum","description":"","date":"2022-09-26","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-09-28-preconditioning-and-element-specific-le","title":"Preconditioning and Element Specific Learning Rate","description":"","date":"2022-09-28","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-10-03-adaptive-learning-rate-and-variance-red","title":"Adaptive Learning Rate and Variance Reduction","description":"","date":"2022-10-03","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-10-05-sparsity-and-dimension-reduction","title":"Sparsity and Dimension Reduction","description":"","date":"2022-10-05","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-10-12-neural-network-review","title":"Neural Network Review","description":"","date":"2022-10-12","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-10-17-accelerate-dnn-training","title":"Accelerate DNN Training","description":"","date":"2022-10-17","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-10-19-beyond-supervised-learning","title":"Beyond supervised learning","description":"","date":"2022-10-19","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-10-24-attention-transformers-and-transfer-lea","title":"Attention, Transformers, and Transfer Learning","description":"","date":"2022-10-24","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2020-10-13-cs4820-intro-to-analysis-of-algorithms","title":"CS4820 Intro to Analysis of Algorithms","description":"","date":"2020-10-13","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","CS4820"],"level":1},{"slug":"2022-02-08-orie4350-game-theory","title":"ORIE4350 Game Theory","description":"","date":"2022-02-08","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1}]}]},"page":{"version":2,"kind":"Article","sha256":"0d5f73812d60f220e69f88588b263de860db74f07b1f91e1ba9811328f2fe955","slug":"2022-10-17-accelerate-dnn-training","location":"/CS4787/2022-10-17-Accelerate-DNN-Training.md","dependencies":[],"frontmatter":{"title":"Accelerate DNN Training","tags":["CS4787"],"date":"2022-10-17","authors":[{"nameParsed":{"literal":"Yao Lirong","given":"Yao","family":"Lirong"},"name":"Yao Lirong","affiliations":["Cornell University"],"url":"https://yao-lirong.github.io","linkedin":"https://www.linkedin.com/in/yao-lirong/","id":"contributors-myst-generated-uid-0"}],"keywords":["Cornell","CS","Yao Lirong"],"affiliations":[{"id":"Cornell University","name":"Cornell University"}],"numbering":{"title":{"offset":1}},"exports":[{"format":"md","filename":"2022-10-17-Accelerate-DNN-Training.md","url":"/cornell-notes/build/2022-10-17-Accelerat-09d4ff2985a6c91f15846c4c761f83c8.md"}]},"mdast":{"type":"root","children":[{"type":"block","children":[{"type":"heading","depth":2,"position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"text","value":"Describing Capacity","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"q1Nlk2VUsb"}],"identifier":"describing-capacity","label":"Describing Capacity","html_id":"describing-capacity","implicit":true,"key":"hqZcU9yK9G"},{"type":"paragraph","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"strong","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"text","value":"Capacity","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"UdfG4V08EB"}],"key":"RO8nHP9QvF"},{"type":"text","value":" of a model informally refers to the ability of the model to fit a wide range of possible functions.","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"km2Ibt3tTV"}],"key":"pLVUZG1WiM"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":12,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"text","value":"Models with high capacity tend to overfit.","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"TFGWsQXmIg"}],"key":"mbPYOGiOYd"},{"type":"listItem","spread":true,"position":{"start":{"line":13,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"text","value":"Models with low capacity tend to underfit.","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"iEtXWDxG4G"}],"key":"OJpsxFpnio"}],"key":"VlLnIbgaJ5"},{"type":"paragraph","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"strong","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"text","value":"Representational Capacity","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"aNByyEYCZ5"}],"key":"g0Hds3yHCg"},{"type":"text","value":" of a model refers to the extent of functions this model can approximate well in theory. Deep neural networks have very high representational capacity. In fact, theyâ€™re universal approximators.","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"ry9AP0a1EU"}],"key":"nnO1vSuMPo"},{"type":"paragraph","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"strong","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"text","value":"Effective Capacity","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"dLMr77nBzI"}],"key":"ubsqVyNu5F"},{"type":"text","value":" of a model refers to the extent of functions this model can approximate well in practice given a specific learning algorithm and dataset.","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"XyqlutUR66"}],"key":"zV8Zpwt3NI"},{"type":"paragraph","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"text","value":"For convex optimization problem, a modelsâ€™ effective capacity is just the representational capacity since local minimum is a global minimum. But for nonconvex problems, a modelâ€™s effective capacity also depends on whether the dataset is representative or whether the learning algorithm is powerful. These two factors can have great effect on effective capacity, though have zero effect on representational capacity.","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"NeCjVou3Pw"}],"key":"UpzAXQqXJR"},{"type":"heading","depth":2,"position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"children":[{"type":"text","value":"Early Stopping","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"OU6Lfienal"}],"identifier":"early-stopping","label":"Early Stopping","html_id":"early-stopping","implicit":true,"key":"z52772gvR3"},{"type":"paragraph","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"children":[{"type":"text","value":"We stop the training when validation loss starts to get bigger.","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"key":"bVFOjohJyY"}],"key":"KHD2FPUtA9"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":25,"column":1},"end":{"line":28,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":25,"column":1},"end":{"line":26,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"children":[{"type":"inlineCode","value":"patience = K","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"key":"duLrRLc7v7"},{"type":"text","value":" - terminate training when validation loss has no improvement in the past K epochs","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"key":"uN7SEyMX23"}],"key":"XprK5yQJ2W"}],"key":"aLpL0Texjj"},{"type":"listItem","spread":true,"position":{"start":{"line":27,"column":1},"end":{"line":28,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":27,"column":1},"end":{"line":27,"column":1}},"children":[{"type":"inlineCode","value":"min_delta=0.01","position":{"start":{"line":27,"column":1},"end":{"line":27,"column":1}},"key":"UaWHVgDCQK"},{"type":"text","value":" - only an improvement greater than 0.01 is considered as an improvement. Anything lower than that is considered as no improvement.","position":{"start":{"line":27,"column":1},"end":{"line":27,"column":1}},"key":"FaBLLHhZUM"}],"key":"Fi0WCCSmGP"}],"key":"USpFxE23aU"}],"key":"b4Q6lbuv06"},{"type":"heading","depth":2,"position":{"start":{"line":29,"column":1},"end":{"line":29,"column":1}},"children":[{"type":"text","value":"Dropout","position":{"start":{"line":29,"column":1},"end":{"line":29,"column":1}},"key":"bNyUlz0B2e"}],"identifier":"dropout","label":"Dropout","html_id":"dropout","implicit":true,"key":"SUpUvZlJhl"},{"type":"paragraph","position":{"start":{"line":31,"column":1},"end":{"line":31,"column":1}},"children":[{"type":"text","value":"During training, randomly drop some neurons (force their activation value to 0) so they do not count as computation. For these neurons, we use 0 to back propagate their values.","position":{"start":{"line":31,"column":1},"end":{"line":31,"column":1}},"key":"MxmYSVovaR"}],"key":"gFWSNXW2xv"},{"type":"paragraph","position":{"start":{"line":33,"column":1},"end":{"line":33,"column":1}},"children":[{"type":"text","value":"In this way, we force all neurons to participate in training: imagine we have two neurons A and B. B always outputs a constant and itâ€™s A always changing to approximate all the values. Now we force A to output 0, B can no longer remain constant and it has to also participate in learning.","position":{"start":{"line":33,"column":1},"end":{"line":33,"column":1}},"key":"sCqSanB6zL"}],"key":"W5mfP0O0Gh"},{"type":"heading","depth":2,"position":{"start":{"line":35,"column":1},"end":{"line":35,"column":1}},"children":[{"type":"text","value":"Batch Normalization","position":{"start":{"line":35,"column":1},"end":{"line":35,"column":1}},"key":"Qc4PASCVll"}],"identifier":"batch-normalization","label":"Batch Normalization","html_id":"batch-normalization","implicit":true,"key":"gtNdt5awE9"},{"type":"paragraph","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"children":[{"type":"text","value":"To avoid great variance in the output of each neuron, we restrain the output of one neuron on a minibatch to have 0 mean and unit standard deviation.","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"key":"Cx0N55wSDG"}],"key":"jVchqqR23a"},{"type":"paragraph","position":{"start":{"line":39,"column":1},"end":{"line":39,"column":1}},"children":[{"type":"text","value":"Think of one specific neuron, let ","position":{"start":{"line":39,"column":1},"end":{"line":39,"column":1}},"key":"XleoIaTbwl"},{"type":"inlineMath","value":"u = [u_1, u_2, \\dots, u_B] \\in \\mathbb R^B","position":{"start":{"line":39,"column":1},"end":{"line":39,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003eu\u003c/mi\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmo stretchy=\"false\"\u003e[\u003c/mo\u003e\u003cmsub\u003e\u003cmi\u003eu\u003c/mi\u003e\u003cmn\u003e1\u003c/mn\u003e\u003c/msub\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmsub\u003e\u003cmi\u003eu\u003c/mi\u003e\u003cmn\u003e2\u003c/mn\u003e\u003c/msub\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmo\u003eâ€¦\u003c/mo\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmsub\u003e\u003cmi\u003eu\u003c/mi\u003e\u003cmi\u003eB\u003c/mi\u003e\u003c/msub\u003e\u003cmo stretchy=\"false\"\u003e]\u003c/mo\u003e\u003cmo\u003eâˆˆ\u003c/mo\u003e\u003cmsup\u003e\u003cmi mathvariant=\"double-struck\"\u003eR\u003c/mi\u003e\u003cmi\u003eB\u003c/mi\u003e\u003c/msup\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eu = [u_1, u_2, \\dots, u_B] \\in \\mathbb R^B\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.4306em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eu\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e[\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003eu\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3011em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e1\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003eâ€‹\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003eu\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3011em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e2\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003eâ€‹\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"minner\"\u003eâ€¦\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003eu\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3283em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.05017em;\"\u003eB\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003eâ€‹\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mclose\"\u003e]\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003eâˆˆ\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8413em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathbb\"\u003eR\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.8413em;\"\u003e\u003cspan style=\"top:-3.063em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.05017em;\"\u003eB\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"B66oxgz4ho"},{"type":"text","value":" be its output for all samples in this batch. Let","position":{"start":{"line":39,"column":1},"end":{"line":39,"column":1}},"key":"Cq9hDjWlj6"}],"key":"IEeYoBcXSB"},{"type":"math","value":"BN(u) = \\frac {u-\\mu} {\\sigma}","position":{"start":{"line":41,"column":1},"end":{"line":43,"column":1}},"html":"\u003cspan class=\"katex-display\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003eB\u003c/mi\u003e\u003cmi\u003eN\u003c/mi\u003e\u003cmo stretchy=\"false\"\u003e(\u003c/mo\u003e\u003cmi\u003eu\u003c/mi\u003e\u003cmo stretchy=\"false\"\u003e)\u003c/mo\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmfrac\u003e\u003cmrow\u003e\u003cmi\u003eu\u003c/mi\u003e\u003cmo\u003eâˆ’\u003c/mo\u003e\u003cmi\u003eÎ¼\u003c/mi\u003e\u003c/mrow\u003e\u003cmi\u003eÏƒ\u003c/mi\u003e\u003c/mfrac\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eBN(u) = \\frac {u-\\mu} {\\sigma}\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.10903em;\"\u003eBN\u003c/span\u003e\u003cspan class=\"mopen\"\u003e(\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eu\u003c/span\u003e\u003cspan class=\"mclose\"\u003e)\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1.9463em;vertical-align:-0.686em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mopen nulldelimiter\"\u003e\u003c/span\u003e\u003cspan class=\"mfrac\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:1.2603em;\"\u003e\u003cspan style=\"top:-2.314em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.03588em;\"\u003eÏƒ\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-3.23em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"frac-line\" style=\"border-bottom-width:0.04em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-3.677em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003eu\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003eâˆ’\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eÎ¼\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003eâ€‹\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.686em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mclose nulldelimiter\"\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","enumerator":"1","key":"BsbgDAGYHC"},{"type":"paragraph","position":{"start":{"line":45,"column":1},"end":{"line":45,"column":1}},"children":[{"type":"text","value":"where ","position":{"start":{"line":45,"column":1},"end":{"line":45,"column":1}},"key":"yMWIwpZEZa"},{"type":"inlineMath","value":"\\mu","position":{"start":{"line":45,"column":1},"end":{"line":45,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003eÎ¼\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\\mu\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.625em;vertical-align:-0.1944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eÎ¼\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"CCu6EPwQiN"},{"type":"text","value":" and ","position":{"start":{"line":45,"column":1},"end":{"line":45,"column":1}},"key":"bs1Sc4c5H6"},{"type":"inlineMath","value":"\\sigma","position":{"start":{"line":45,"column":1},"end":{"line":45,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003eÏƒ\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\\sigma\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.4306em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.03588em;\"\u003eÏƒ\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"s92aOUcfi2"},{"type":"text","value":" are the mean and standard deviation of ","position":{"start":{"line":45,"column":1},"end":{"line":45,"column":1}},"key":"Ln5g7NtiKR"},{"type":"inlineMath","value":"u = [u_1, u_2, \\dots, u_B]","position":{"start":{"line":45,"column":1},"end":{"line":45,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003eu\u003c/mi\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmo stretchy=\"false\"\u003e[\u003c/mo\u003e\u003cmsub\u003e\u003cmi\u003eu\u003c/mi\u003e\u003cmn\u003e1\u003c/mn\u003e\u003c/msub\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmsub\u003e\u003cmi\u003eu\u003c/mi\u003e\u003cmn\u003e2\u003c/mn\u003e\u003c/msub\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmo\u003eâ€¦\u003c/mo\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmsub\u003e\u003cmi\u003eu\u003c/mi\u003e\u003cmi\u003eB\u003c/mi\u003e\u003c/msub\u003e\u003cmo stretchy=\"false\"\u003e]\u003c/mo\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eu = [u_1, u_2, \\dots, u_B]\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.4306em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eu\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e[\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003eu\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3011em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e1\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003eâ€‹\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003eu\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3011em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e2\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003eâ€‹\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"minner\"\u003eâ€¦\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003eu\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3283em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.05017em;\"\u003eB\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003eâ€‹\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mclose\"\u003e]\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"AfytkuzSEt"},{"type":"text","value":". After BN layer, it has 0 mean and unit sd.","position":{"start":{"line":45,"column":1},"end":{"line":45,"column":1}},"key":"W9flbFwzNv"}],"key":"va61RDLMXy"},{"type":"paragraph","position":{"start":{"line":47,"column":1},"end":{"line":47,"column":1}},"children":[{"type":"text","value":"This is how we calculate BN during training. In training, we also keep an ","position":{"start":{"line":47,"column":1},"end":{"line":47,"column":1}},"key":"sMEfXC1g0z"},{"type":"strong","position":{"start":{"line":47,"column":1},"end":{"line":47,"column":1}},"children":[{"type":"text","value":"exponential running average","position":{"start":{"line":47,"column":1},"end":{"line":47,"column":1}},"key":"rtHrO3xP96"}],"key":"Jr6GMKwJuA"},{"type":"text","value":" of ","position":{"start":{"line":47,"column":1},"end":{"line":47,"column":1}},"key":"pZFT3YcFGL"},{"type":"inlineMath","value":"\\mu","position":{"start":{"line":47,"column":1},"end":{"line":47,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003eÎ¼\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\\mu\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.625em;vertical-align:-0.1944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eÎ¼\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"g8b29pJhFx"},{"type":"text","value":" and ","position":{"start":{"line":47,"column":1},"end":{"line":47,"column":1}},"key":"fvfO1MZhLZ"},{"type":"inlineMath","value":"\\sigma^2","position":{"start":{"line":47,"column":1},"end":{"line":47,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsup\u003e\u003cmi\u003eÏƒ\u003c/mi\u003e\u003cmn\u003e2\u003c/mn\u003e\u003c/msup\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\\sigma^2\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8141em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.03588em;\"\u003eÏƒ\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.8141em;\"\u003e\u003cspan style=\"top:-3.063em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e2\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"OfApUKSVSX"},{"type":"text","value":", so ","position":{"start":{"line":47,"column":1},"end":{"line":47,"column":1}},"key":"bXLM6mcucO"},{"type":"strong","position":{"start":{"line":47,"column":1},"end":{"line":47,"column":1}},"children":[{"type":"text","value":"during evaluation","position":{"start":{"line":47,"column":1},"end":{"line":47,"column":1}},"key":"IgNx5ILD2P"}],"key":"iFlVIVnuet"},{"type":"text","value":", we use these averages as the batch statistics. Batch Norm is usually ","position":{"start":{"line":47,"column":1},"end":{"line":47,"column":1}},"key":"X3sPUBMILf"},{"type":"strong","position":{"start":{"line":47,"column":1},"end":{"line":47,"column":1}},"children":[{"type":"text","value":"applied before activation","position":{"start":{"line":47,"column":1},"end":{"line":47,"column":1}},"key":"y7qVezXqZX"}],"key":"NtBx1I05RE"},{"type":"text","value":".","position":{"start":{"line":47,"column":1},"end":{"line":47,"column":1}},"key":"G1hHIBJ6Jf"}],"key":"bqAVbPxNu8"},{"type":"paragraph","position":{"start":{"line":49,"column":1},"end":{"line":49,"column":1}},"children":[{"type":"text","value":"There are two problems with Batch Norm:","position":{"start":{"line":49,"column":1},"end":{"line":49,"column":1}},"key":"VgghhNx9jg"}],"key":"CMwpYN03uQ"},{"type":"list","ordered":true,"start":1,"spread":false,"position":{"start":{"line":51,"column":1},"end":{"line":62,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":51,"column":1},"end":{"line":60,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":51,"column":1},"end":{"line":51,"column":1}},"children":[{"type":"text","value":"We effectively reduced the representative capacity of our model by constraining mean to only be 0 and sd to only be 1. Note previously, each neuron can have different mean and sd, but now they all have the same.","position":{"start":{"line":51,"column":1},"end":{"line":51,"column":1}},"key":"imgWTVUOeb"}],"key":"G5JXuStb3l"},{"type":"paragraph","position":{"start":{"line":53,"column":1},"end":{"line":53,"column":1}},"children":[{"type":"text","value":"We try to solve this problem by adding an affine term to assign a new non-zero mean ","position":{"start":{"line":53,"column":1},"end":{"line":53,"column":1}},"key":"tMDy0g2R6d"},{"type":"inlineMath","value":"\\beta","position":{"start":{"line":53,"column":1},"end":{"line":53,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003eÎ²\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\\beta\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.05278em;\"\u003eÎ²\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"t7W4KjUsB4"},{"type":"text","value":" and a new non-unit sd ","position":{"start":{"line":53,"column":1},"end":{"line":53,"column":1}},"key":"PefTVk7L8C"},{"type":"inlineMath","value":"\\gamma","position":{"start":{"line":53,"column":1},"end":{"line":53,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003eÎ³\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\\gamma\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.625em;vertical-align:-0.1944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.05556em;\"\u003eÎ³\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"bOgTxexEd4"},{"type":"text","value":" to the activation value on this batch from this neuron. ","position":{"start":{"line":53,"column":1},"end":{"line":53,"column":1}},"key":"RIxcFoLfY3"},{"type":"inlineMath","value":"\\gamma, \\beta","position":{"start":{"line":53,"column":1},"end":{"line":53,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003eÎ³\u003c/mi\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmi\u003eÎ²\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\\gamma, \\beta\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.05556em;\"\u003eÎ³\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.05278em;\"\u003eÎ²\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"JAn24UeMfw"},{"type":"text","value":" are two learnable terms here. (Note ","position":{"start":{"line":53,"column":1},"end":{"line":53,"column":1}},"key":"TnzN4EI6de"},{"type":"inlineMath","value":"\\mu, \\sigma, \\gamma, \\beta","position":{"start":{"line":53,"column":1},"end":{"line":53,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003eÎ¼\u003c/mi\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmi\u003eÏƒ\u003c/mi\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmi\u003eÎ³\u003c/mi\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmi\u003eÎ²\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\\mu, \\sigma, \\gamma, \\beta\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eÎ¼\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.03588em;\"\u003eÏƒ\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.05556em;\"\u003eÎ³\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.05278em;\"\u003eÎ²\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"mYPMwcFuMG"},{"type":"text","value":" are all scalars here)","position":{"start":{"line":53,"column":1},"end":{"line":53,"column":1}},"key":"HDKCRkp0jS"}],"key":"bReLhrHH5e"},{"type":"math","value":"BN(u) = \\frac {u-\\mu} {\\sigma} \\gamma + \\beta","position":{"start":{"line":55,"column":1},"end":{"line":57,"column":1}},"html":"\u003cspan class=\"katex-display\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003eB\u003c/mi\u003e\u003cmi\u003eN\u003c/mi\u003e\u003cmo stretchy=\"false\"\u003e(\u003c/mo\u003e\u003cmi\u003eu\u003c/mi\u003e\u003cmo stretchy=\"false\"\u003e)\u003c/mo\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmfrac\u003e\u003cmrow\u003e\u003cmi\u003eu\u003c/mi\u003e\u003cmo\u003eâˆ’\u003c/mo\u003e\u003cmi\u003eÎ¼\u003c/mi\u003e\u003c/mrow\u003e\u003cmi\u003eÏƒ\u003c/mi\u003e\u003c/mfrac\u003e\u003cmi\u003eÎ³\u003c/mi\u003e\u003cmo\u003e+\u003c/mo\u003e\u003cmi\u003eÎ²\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eBN(u) = \\frac {u-\\mu} {\\sigma} \\gamma + \\beta\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.10903em;\"\u003eBN\u003c/span\u003e\u003cspan class=\"mopen\"\u003e(\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eu\u003c/span\u003e\u003cspan class=\"mclose\"\u003e)\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1.9463em;vertical-align:-0.686em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mopen nulldelimiter\"\u003e\u003c/span\u003e\u003cspan class=\"mfrac\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:1.2603em;\"\u003e\u003cspan style=\"top:-2.314em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.03588em;\"\u003eÏƒ\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-3.23em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"frac-line\" style=\"border-bottom-width:0.04em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-3.677em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003eu\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003eâˆ’\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eÎ¼\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003eâ€‹\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.686em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mclose nulldelimiter\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.05556em;\"\u003eÎ³\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e+\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.05278em;\"\u003eÎ²\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","enumerator":"2","key":"JkWuhIFJyz"},{"type":"paragraph","position":{"start":{"line":59,"column":1},"end":{"line":59,"column":1}},"children":[{"type":"text","value":"However, doesnâ€™t this defeat the purpose of normalizing in the first place? This considered, the above equation is still the common practice though we donâ€™t know why it works","position":{"start":{"line":59,"column":1},"end":{"line":59,"column":1}},"key":"yxTFsI4YUe"}],"key":"a6rMlVAxO7"}],"key":"OsITQRq48e"},{"type":"listItem","spread":true,"position":{"start":{"line":61,"column":1},"end":{"line":62,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":61,"column":1},"end":{"line":61,"column":1}},"children":[{"type":"text","value":"All previous proofs depend on the fact that calculation of gradient step on each sample in minibatch is independent. However, by adding the mean ","position":{"start":{"line":61,"column":1},"end":{"line":61,"column":1}},"key":"utSHL5VE7C"},{"type":"inlineMath","value":"\\mu","position":{"start":{"line":61,"column":1},"end":{"line":61,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003eÎ¼\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\\mu\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.625em;vertical-align:-0.1944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eÎ¼\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"Dc66UCVxzC"},{"type":"text","value":" and sd ","position":{"start":{"line":61,"column":1},"end":{"line":61,"column":1}},"key":"yVck8jK011"},{"type":"inlineMath","value":"\\sigma","position":{"start":{"line":61,"column":1},"end":{"line":61,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003eÏƒ\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\\sigma\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.4306em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.03588em;\"\u003eÏƒ\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"dZEXyS0C7k"},{"type":"text","value":", we make the update step dependent of each other, since mean and sd depend on all samples. This nullifies all the proofs we did previously ensuring good properties of SGD. Despite this, it performs good and people use it.","position":{"start":{"line":61,"column":1},"end":{"line":61,"column":1}},"key":"CS1oDDLXao"}],"key":"UbyruhPK4U"}],"key":"yovfU3soMg"}],"key":"KQd2anRH4c"},{"type":"heading","depth":2,"position":{"start":{"line":63,"column":1},"end":{"line":63,"column":1}},"children":[{"type":"text","value":"Residual Block / Skip Connection","position":{"start":{"line":63,"column":1},"end":{"line":63,"column":1}},"key":"ZNCc8sQCFL"}],"identifier":"residual-block-skip-connection","label":"Residual Block / Skip Connection","html_id":"residual-block-skip-connection","implicit":true,"key":"sm6vRZmKgi"},{"type":"code","lang":"","value":"L0 ---- L1 ---- sigma1 ---- L2 ---- sigma2 --+--\n     |                                       |\n     -----------------------------------------","position":{"start":{"line":65,"column":1},"end":{"line":69,"column":1}},"key":"jHedbS7tgv"},{"type":"paragraph","position":{"start":{"line":71,"column":1},"end":{"line":71,"column":1}},"children":[{"type":"text","value":"The L here are some computation layers and sigma is the non-linear activation layer.","position":{"start":{"line":71,"column":1},"end":{"line":71,"column":1}},"key":"dytxQgIlnh"}],"key":"DuGE69TYNP"},{"type":"paragraph","position":{"start":{"line":73,"column":1},"end":{"line":73,"column":1}},"children":[{"type":"text","value":"So why do we add this skip connection? Imagine L2 does something weird that prevent learning (maybe all its weights go to 0, so gradient of this point to earlier layers all go to 0 when we compute it in back propagation). By adding L0 value, we ensure that even if L2 doesnâ€™t work, the whole network can still work (for this particular example, we can then make L0 gradient non-zero even whatâ€™s in between all have gradient 0)","position":{"start":{"line":73,"column":1},"end":{"line":73,"column":1}},"key":"UcRrsLzYJU"}],"key":"F1yWcy5edm"},{"type":"paragraph","position":{"start":{"line":75,"column":1},"end":{"line":75,"column":1}},"children":[{"type":"text","value":"The classic ResNet employs this architecture:","position":{"start":{"line":75,"column":1},"end":{"line":75,"column":1}},"key":"gXBb5h6JU0"}],"key":"xtmXLC8SlD"},{"type":"code","lang":"","value":"L0 ---- conv1 ---- BN1 ---- sigma1 ---- conv2 ---- BN2 --+-- sigma2\n     |                                                   |\n     -----------------------------------------------------","position":{"start":{"line":77,"column":1},"end":{"line":81,"column":1}},"key":"BKVS1asoRO"},{"type":"code","lang":"python","value":"# https://github.com/akamaster/pytorch_resnet_cifar10/blob/master/resnet.py/ class BasicBlock\ndef forward(self, x):\n    out = F.relu(self.bn1(self.conv1(x)))\n    out = self.bn2(self.conv2(out))\n    out += self.shortcut(x)\n    out = F.relu(out)\n    return out","position":{"start":{"line":83,"column":1},"end":{"line":91,"column":1}},"key":"eIGe1jOC7W"},{"type":"paragraph","position":{"start":{"line":93,"column":1},"end":{"line":93,"column":1}},"children":[{"type":"text","value":"People donâ€™t usually relate this to RNN because an RNN takes in sequence of inputs and each token of it is passed into the same weight / model.","position":{"start":{"line":93,"column":1},"end":{"line":93,"column":1}},"key":"afpM7CeTSP"}],"key":"cI6aacsc2S"}],"key":"h3hOccvHhE"}],"key":"nWjR3cIFn8"},"references":{"cite":{"order":[],"data":{}}},"footer":{"navigation":{"prev":{"title":"Neural Network Review","url":"/2022-10-12-neural-network-review","group":"CS4787 Principles of Large-Scale Machine Learning"},"next":{"title":"Beyond supervised learning","url":"/2022-10-19-beyond-supervised-learning","group":"CS4787 Principles of Large-Scale Machine Learning"}}},"domain":"http://localhost:3000"},"project":{"title":"Incomplete CS Notes @ Cornell","description":"This is a complete collection of course notes I've taken when studying CS at Cornell University","authors":[{"nameParsed":{"literal":"Yao Lirong","given":"Yao","family":"Lirong"},"name":"Yao Lirong","affiliations":["Cornell University"],"url":"https://yao-lirong.github.io","linkedin":"https://www.linkedin.com/in/yao-lirong/","id":"contributors-myst-generated-uid-0"}],"keywords":["Cornell","CS","Yao Lirong"],"affiliations":[{"id":"Cornell University","name":"Cornell University"}],"id":"dbd3e509-63c9-4982-a7c3-5cf505dc3c02","toc":[{"file":"index.md"},{"file":"2020-10-02-INFO1998-Intro-to-Machine-Learning.md"},{"file":"2020-09-07-CS2024-C++-Programming.md"},{"children":[{"file":"CS2112/2019-09-24-Generics.md"},{"file":"CS2112/2019-09-30-Value-Representation,-Hashing,-and-Generics.md"},{"file":"CS2112/2019-10-08-Parsing.md"},{"file":"CS2112/2019-10-17-Designing-and-documenting-interfaces-and-implementations.md"},{"file":"CS2112/2019-10-24-Design-Pattern.md"},{"file":"CS2112/2019-10-29 Event Handlers.md"},{"file":"CS2112/2019-11-07-Concurrency.md"},{"file":"CS2112/2019-11-12-synchronization.md"},{"file":"CS2112/2019-11-19-Graph-Traversal.md"},{"file":"CS2112/2019-11-20-Graph-(Recitation).md"},{"file":"CS2112/2019-11-21-shortest-path-algorithm.md"},{"file":"CS2112/2019-11-23-Android-Basics-User-Interface.md"},{"file":"CS2112/2019-11-26-Priority-Queue-and-Heap.md"},{"file":"CS2112/2019-12-05-Problem-Analysis.md"}],"title":"CS2112 Object-Oriented Design (Honors)"},{"children":[{"file":"CS3110/2020-01-28-Functions.md"},{"file":"CS3110/2020-01-30-Standard-Data-Types.md"},{"file":"CS3110/2020-02-04-Advanced-Data-Types.md"},{"file":"CS3110/2020-02-06-Higher-Order-Functions.md"},{"file":"CS3110/2020-02-11-Modules.md"},{"file":"CS3110/2020-02-13-Code-Reuse-with-Modules.md"},{"file":"CS3110/2020-02-18-Specifications.md"},{"file":"CS3110/2020-03-03-Mutability.md"},{"file":"CS3110/2020-04-06-Red-Black-Tree.md"},{"file":"CS3110/2020-04-09-Interpreter.md"},{"file":"CS3110/2020-04-14-The-Substitution-Model.md"},{"file":"CS3110/2020-04-16-The-Environment-Model.md"}],"title":"CS3110 Functional Programming"},{"children":[{"file":"CS4780/2021-08-31-Machine-Learning-Basics.md"},{"file":"CS4780/2021-09-02-K-Nearest-Neighbors.md"},{"file":"CS4780/2021-09-07-K-means-clustering.md"},{"file":"CS4780/2021-09-09-Principal-Component-Analysis.md"},{"file":"CS4780/2021-09-14-The-Perceptron.md"},{"file":"CS4780/2021-09-16-MLE-and-MAP.md"},{"file":"CS4780/2021-09-21-Naive-Bayes.md"},{"file":"CS4780/2021-09-28-Logistic-Regression.md"},{"file":"CS4780/2021-09-30-Gradient-Descent.md"},{"file":"CS4780/2021-10-05-Important-Distributions-and-Linear-Regression.md"},{"file":"CS4780/2021-10-07-SVM---Support-Vector-Machine.md"},{"file":"CS4780/2021-10-14-Empirical-Risk-Minimization.md"},{"file":"CS4780/2021-10-19-Midterm-Review.md"},{"file":"CS4780/2021-10-26-Bias-Variance-Tradeoff.md"},{"file":"CS4780/2021-10-28-Model-Selection-Tricks.md"},{"file":"CS4780/2021-11-02-Kernels.md"},{"file":"CS4780/2021-11-04-More-on-Kernels.md"},{"file":"CS4780/2021-11-09-Decision-Tree.md"},{"file":"CS4780/2021-11-16-Bagging.md"},{"file":"CS4780/2021-11-18-Boosting.md"}],"title":"CS4780 Intro to Machine Learning"},{"children":[{"file":"CS4787/2022-08-22-Introduction.md"},{"file":"CS4787/2022-08-24-Linear-Algebra-and-NumPy.md"},{"file":"CS4787/2022-08-29-Automatic-Differentiation.md"},{"file":"CS4787/2022-08-31-Back-Propagation.md"},{"file":"CS4787/2022-09-12-Gradient-Descent.md"},{"file":"CS4787/2022-09-14-Gradient-Descent-and-Convexity.md"},{"file":"CS4787/2022-09-19-Stochastic-Gradient-Descent.md"},{"file":"CS4787/2022-09-21-Stochastic-Gradient-Descent-Improved.md"},{"file":"CS4787/2022-09-26-SGD-with-Momentum.md"},{"file":"CS4787/2022-09-28-Preconditioning-and-Element-Specific-Learning-Rate.md"},{"file":"CS4787/2022-10-03-Adaptive-Learning-Rate-and-Variance-Reduction.md"},{"file":"CS4787/2022-10-05-Sparsity-and-Dimension-Reduction.md"},{"file":"CS4787/2022-10-12-Neural-Network-Review.md"},{"file":"CS4787/2022-10-17-Accelerate-DNN-Training.md"},{"file":"CS4787/2022-10-19-Beyond-supervised-learning.md"},{"file":"CS4787/2022-10-24-Attention,-Transformers,-and-Transfer-Learning.md"}],"title":"CS4787 Principles of Large-Scale Machine Learning"},{"file":"2020-10-13-CS4820-Intro-to-Analysis-of-Algorithms.md"},{"file":"2022-02-08-ORIE4350-Game-Theory.md"}],"thumbnail":"/cornell-notes/build/cornhell-37b881e150badb60bb90a0054b1665ba.png","exports":[],"bibliography":[],"index":"index","pages":[{"slug":"2020-10-02-info1998-intro-to-machine-learning","title":"INFO1998 Intro to Machine Learning","description":"","date":"2020-10-02","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20FA","Python"],"level":1},{"slug":"2020-09-07-cs2024-c-programming","title":"CS2024 C++ Programming","description":"","date":"2020-09-07","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","CS2024","20FA"],"level":1},{"level":1,"title":"CS2112 Object-Oriented Design (Honors)"},{"slug":"2019-09-24-generics","title":"Generics","description":"","date":"2019-09-24","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","19FA","CS2112"],"level":2},{"slug":"2019-09-30-value-representation-hashing-and-generi","title":"Value Representation, Hashing, and Generics","description":"","date":"2019-09-30","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","FA19","CS2112"],"level":2},{"slug":"2019-10-08-parsing","title":"Parsing","description":"","date":"2019-10-08","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","19FA","CS2112"],"level":2},{"slug":"2019-10-17-designing-and-documenting-interfaces-an","title":"Designing and documenting interfaces and implementations","description":"","date":"2019-10-17","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","19FA","CS2112"],"level":2},{"slug":"2019-10-24-design-pattern","title":"Design Pattern","description":"","date":"2019-10-24","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","19FA","CS2112"],"level":2},{"slug":"2019-10-29-event-handlers","title":"Building GUI","description":"","date":"2019-10-29","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","19FA","CS2112"],"level":2},{"slug":"2019-11-07-concurrency","title":"Concurrency","description":"","date":"2019-11-07","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","19FA","CS2112"],"level":2},{"slug":"2019-11-12-synchronization","title":"Synchronization","description":"","date":"2019-11-12","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","19FA","CS2112"],"level":2},{"slug":"2019-11-19-graph-traversal","title":"Graph Traversal","description":"","date":"2019-11-19","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","19FA","CS2112"],"level":2},{"slug":"2019-11-20-graph-recitation","title":"Graph (Recitation)","description":"","date":"2019-11-20","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","19FA","CS2112"],"level":2},{"slug":"2019-11-21-shortest-path-algorithm","title":"shortest path algorithm","description":"","date":"2019-11-21","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","CS2112"],"level":2},{"slug":"2019-11-23-android-basics-user-interface","title":"Udacity: Android Basics","description":"","date":"2019-11-23","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Android"],"level":2},{"slug":"2019-11-26-priority-queue-and-heap","title":"Priority Queue and Heap","description":"","date":"2019-11-26","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","CS2112"],"level":2},{"slug":"2019-12-05-problem-analysis","title":"Problem Analysis","description":"","date":"2019-12-05","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","CS2112"],"level":2},{"level":1,"title":"CS3110 Functional Programming"},{"slug":"2020-01-28-functions","title":"Functions","description":"","date":"2020-01-28","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"slug":"2020-01-30-standard-data-types","title":"Standard Data Types","description":"","date":"2020-01-30","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"slug":"2020-02-04-advanced-data-types","title":"Advanced Data Types","description":"","date":"2020-02-04","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"slug":"2020-02-06-higher-order-functions","title":"Higher-Order Functions","description":"","date":"2020-02-06","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"slug":"2020-02-11-modules","title":"Modules","description":"","date":"2020-02-11","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"slug":"2020-02-13-code-reuse-with-modules","title":"Code Reuse with Modules","description":"","date":"2020-02-13","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"slug":"2020-02-18-specifications","title":"Specifications","description":"","date":"2020-02-18","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"slug":"2020-03-03-mutability","title":"Mutability","description":"","date":"2020-03-03","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"slug":"2020-04-06-red-black-tree","title":"Red Black Tree","description":"","date":"2020-04-06","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","CS3110","20SP"],"level":2},{"slug":"2020-04-09-interpreter","title":"Interpreter","description":"","date":"2020-04-09","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"slug":"2020-04-14-the-substitution-model","title":"The Substitution Model","description":"","date":"2020-04-14","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"slug":"2020-04-16-the-environment-model","title":"The Environment Model","description":"","date":"2020-04-16","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"level":1,"title":"CS4780 Intro to Machine Learning"},{"slug":"2021-08-31-machine-learning-basics","title":"Machine Learning Basics","description":"","date":"2021-08-31","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS"],"level":2},{"slug":"2021-09-02-k-nearest-neighbors","title":"K-Nearest Neighbors","description":"","date":"2021-09-02","thumbnail":"/cornell-notes/build/d2d32ed7f030408c4751b4082cc4c4fb.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-09-07-k-means-clustering","title":"K-means clustering","description":"","date":"2021-09-07","thumbnail":"/cornell-notes/build/2b624c0dfc4541e6702d7d03a35846a3.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-09-09-principal-component-analysis","title":"Principal Component Analysis","description":"","date":"2021-09-09","thumbnail":"/cornell-notes/build/0f82a0d8a1b909f3be9ff331e1e605e3.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-09-14-the-perceptron","title":"The Perceptron","description":"","date":"2021-09-14","thumbnail":"/cornell-notes/build/0561dbd9a0937d3d1decc2a2e9d7a150.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-09-16-mle-and-map","title":"MLE and MAP","description":"","date":"2021-09-16","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-09-21-naive-bayes","title":"Naive Bayes","description":"","date":"2021-09-21","thumbnail":"/cornell-notes/build/1dec3195698f490f89eb8383ef29b8c8.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-09-28-logistic-regression","title":"Logistic Regression","description":"","date":"2021-09-28","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-09-30-gradient-descent","title":"Gradient Descent","description":"","date":"2021-09-30","thumbnail":"/cornell-notes/build/e3d52da6368f919deb4783b786520acd.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-10-05-important-distributions-and-linear-regr","title":"Important Distributions and Linear Regression","description":"","date":"2021-10-05","thumbnail":"/cornell-notes/build/023faa064932bbe5ec11298e7cbdbdbd.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-10-07-svm-support-vector-machine","title":"SVM - Support Vector Machine","description":"","date":"2021-10-07","thumbnail":"/cornell-notes/build/41379864e80001dd60125813623c4915.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-10-14-empirical-risk-minimization","title":"Empirical Risk Minimization","description":"","date":"2021-10-14","thumbnail":"/cornell-notes/build/f9e37f639bf7ed7d0e0daf5d55dee992.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-10-19-midterm-review","title":"Midterm Review","description":"","date":"2021-10-19","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-10-26-bias-variance-tradeoff","title":"Bias-Variance Tradeoff","description":"","date":"2021-10-26","thumbnail":"/cornell-notes/build/92f79954ba3e60170a726689263cc46c.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-10-28-model-selection-tricks","title":"Model Selection Tricks","description":"","date":"2021-10-28","thumbnail":"/cornell-notes/build/643c4fcd86a736a95208145a3a53f8ee.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-11-02-kernels","title":"Kernels","description":"","date":"2021-11-02","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-11-04-more-on-kernels","title":"More on Kernels","description":"","date":"2021-11-04","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-11-09-decision-tree","title":"Decision Tree","description":"","date":"2021-11-09","thumbnail":"/cornell-notes/build/2f6b3cd8046659d873cef1793b421adf.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-11-16-bagging","title":"Bagging","description":"","date":"2021-11-16","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-11-18-boosting","title":"Boosting","description":"","date":"2021-11-18","thumbnail":"/cornell-notes/build/315b0684d85fc252232fdf8cba2a9c87.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"CS4787 Principles of Large-Scale Machine Learning"},{"slug":"2022-08-22-introduction","title":"Introduction","description":"","date":"2022-08-22","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-08-24-linear-algebra-and-numpy","title":"Linear Algebra and NumPy","description":"","date":"2022-08-24","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-08-29-automatic-differentiation","title":"Automatic Differentiation","description":"","date":"2022-08-29","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-08-31-back-propagation","title":"Back Propagation","description":"","date":"2022-08-31","thumbnail":"/cornell-notes/build/9a793e5d3b94eacefaeb4ada8b427898.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-09-12-gradient-descent","title":"Gradient Descent","description":"","date":"2022-09-12","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-09-14-gradient-descent-and-convexity","title":"Gradient Descent and Convexity","description":"","date":"2022-09-14","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-09-19-stochastic-gradient-descent","title":"Stochastic Gradient Descent","description":"","date":"2022-09-19","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-09-21-stochastic-gradient-descent-improved","title":"Stochastic Gradient Descent Improved","description":"","date":"2022-09-21","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-09-26-sgd-with-momentum","title":"SGD with Momentum","description":"","date":"2022-09-26","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-09-28-preconditioning-and-element-specific-le","title":"Preconditioning and Element Specific Learning Rate","description":"","date":"2022-09-28","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-10-03-adaptive-learning-rate-and-variance-red","title":"Adaptive Learning Rate and Variance Reduction","description":"","date":"2022-10-03","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-10-05-sparsity-and-dimension-reduction","title":"Sparsity and Dimension Reduction","description":"","date":"2022-10-05","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-10-12-neural-network-review","title":"Neural Network Review","description":"","date":"2022-10-12","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-10-17-accelerate-dnn-training","title":"Accelerate DNN Training","description":"","date":"2022-10-17","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-10-19-beyond-supervised-learning","title":"Beyond supervised learning","description":"","date":"2022-10-19","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-10-24-attention-transformers-and-transfer-lea","title":"Attention, Transformers, and Transfer Learning","description":"","date":"2022-10-24","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2020-10-13-cs4820-intro-to-analysis-of-algorithms","title":"CS4820 Intro to Analysis of Algorithms","description":"","date":"2020-10-13","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","CS4820"],"level":1},{"slug":"2022-02-08-orie4350-game-theory","title":"ORIE4350 Game Theory","description":"","date":"2022-02-08","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1}]}}},"actionData":null,"errors":null},"future":{"unstable_dev":false,"unstable_postcss":false,"unstable_tailwind":false,"v2_errorBoundary":true,"v2_headers":true,"v2_meta":true,"v2_normalizeFormMethod":true,"v2_routeConvention":true}};</script><script type="module" async="">import "/cornell-notes/build/manifest-7CA79D5B.js";
import * as route0 from "/cornell-notes/build/root-LY5YATWI.js";
import * as route1 from "/cornell-notes/build/routes/$-RAODST7L.js";
window.__remixRouteModules = {"root":route0,"routes/$":route1};

import("/cornell-notes/build/entry.client-UNPC4GT3.js");</script></body></html>