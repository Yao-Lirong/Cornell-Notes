{"version":2,"kind":"Article","sha256":"8c52e5ea1be25b7b9d2cc6cdae9943e9843fd289794b9e347e37a89f0ab57838","slug":"2022-10-12-neural-network-review","location":"/CS4787/2022-10-12-Neural-Network-Review.md","dependencies":[],"frontmatter":{"title":"Neural Network Review","tags":["CS4787"],"date":"2022-10-12","authors":[{"nameParsed":{"literal":"Yao Lirong","given":"Yao","family":"Lirong"},"name":"Yao Lirong","affiliations":["Cornell University"],"url":"https://yao-lirong.github.io","linkedin":"https://www.linkedin.com/in/yao-lirong/","id":"contributors-myst-generated-uid-0"}],"keywords":["Cornell","CS","Yao Lirong"],"affiliations":[{"id":"Cornell University","name":"Cornell University"}],"numbering":{"title":{"offset":1}},"exports":[{"format":"md","filename":"2022-10-12-Neural-Network-Review.md","url":"/cornell-notes/build/2022-10-12-Neural-Ne-925b1b77ff6fc31fffcc0845a468c63f.md"}]},"mdast":{"type":"root","children":[{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"text","value":"In a deep neural network, we have all those non linear layers and they contribute to the unconvexity of the loss function. In the optimization regime, when we have some problem as unconvex, we regard it as hard to solve. However in practice, the convex optimization algorithms we have discussed so far do perform well on Neural Networks.","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"qtKqzYrqtX"}],"key":"i9M3KXrLY9"},{"type":"paragraph","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"text","value":"NN tends not to overfit. We have this nice property of double descent that after the regime of overfit, if we continue growing the model size to a super huge model, the testing error will actually go down again (as we see in GPT-3 level model)","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"PCn2AU6deP"}],"key":"GZhJYwR3WR"}],"key":"YF6P7WcaGR"}],"key":"wUoEaneu8U"},"references":{"cite":{"order":[],"data":{}}},"footer":{"navigation":{"prev":{"title":"Sparsity and Dimension Reduction","url":"/2022-10-05-sparsity-and-dimension-reduction","group":"CS4787 Principles of Large-Scale Machine Learning"},"next":{"title":"Accelerate DNN Training","url":"/2022-10-17-accelerate-dnn-training","group":"CS4787 Principles of Large-Scale Machine Learning"}}},"domain":"http://localhost:3000"}