<!DOCTYPE html><html lang="en" class="" style="scroll-padding:60px"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width,initial-scale=1"/><title>INFO1998 Intro to Machine Learning - Incomplete CS Notes @ Cornell</title><meta property="og:title" content="INFO1998 Intro to Machine Learning - Incomplete CS Notes @ Cornell"/><meta name="generator" content="mystmd"/><meta name="description" content="This is a complete collection of course notes I&#x27;ve taken when studying CS at Cornell University"/><meta property="og:description" content="This is a complete collection of course notes I&#x27;ve taken when studying CS at Cornell University"/><meta name="keywords" content="Cornell, CS, Yao Lirong"/><meta name="image" content="/cornell-notes/build/cornhell-37b881e150badb60bb90a0054b1665ba.png"/><meta property="og:image" content="/cornell-notes/build/cornhell-37b881e150badb60bb90a0054b1665ba.png"/><link rel="stylesheet" href="/cornell-notes/build/_assets/app-5WKS5EPQ.css"/><link rel="stylesheet" href="/cornell-notes/build/_assets/thebe-core-VKVHG5VY.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jupyter-matplotlib@0.11.3/css/mpl_widget.css"/><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css" integrity="sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ" crossorigin="anonymous"/><link rel="icon" href="/cornell-notes/favicon.ico"/><link rel="stylesheet" href="/cornell-notes/myst-theme.css"/><script>
  const savedTheme = localStorage.getItem("myst:theme");
  const theme = window.matchMedia("(prefers-color-scheme: light)").matches ? 'light' : 'dark';
  const classes = document.documentElement.classList;
  const hasAnyTheme = classes.contains('light') || classes.contains('dark');
  if (!hasAnyTheme) classes.add(savedTheme ?? theme);
</script></head><body class="m-0 transition-colors duration-500 bg-white dark:bg-stone-900"><div class="fixed top-1 left-1 h-[0px] w-[0px] focus-within:z-40 focus-within:h-auto focus-within:w-auto bg-white overflow-hidden focus-within:p-2 focus-within:ring-1" aria-label="skip to content options"><a href="#skip-to-frontmatter" class="block px-2 py-1 text-black underline">Skip to article frontmatter</a><a href="#skip-to-article" class="block px-2 py-1 text-black underline">Skip to article content</a></div><div class="bg-white/80 backdrop-blur dark:bg-stone-900/80 shadow dark:shadow-stone-700 p-3 md:px-8 sticky w-screen top-0 z-30 h-[60px]"><nav class="flex items-center justify-between flex-nowrap max-w-[1440px] mx-auto"><div class="flex flex-row xl:min-w-[19.5rem] mr-2 sm:mr-7 justify-start items-center shrink-0"><div class="block xl:hidden"><button class="flex items-center border-stone-400 text-stone-800 hover:text-stone-900 dark:text-stone-200 hover:dark:text-stone-100"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" width="2rem" height="2rem" class="m-1"><path fill-rule="evenodd" d="M3 6.75A.75.75 0 0 1 3.75 6h16.5a.75.75 0 0 1 0 1.5H3.75A.75.75 0 0 1 3 6.75ZM3 12a.75.75 0 0 1 .75-.75h16.5a.75.75 0 0 1 0 1.5H3.75A.75.75 0 0 1 3 12Zm0 5.25a.75.75 0 0 1 .75-.75h16.5a.75.75 0 0 1 0 1.5H3.75a.75.75 0 0 1-.75-.75Z" clip-rule="evenodd"></path></svg><span class="sr-only">Open Menu</span></button></div><a class="flex items-center ml-3 dark:text-white w-fit md:ml-5 xl:ml-7" href="/cornell-notes/"><div class="p-1 mr-3 dark:bg-white dark:rounded"><img src="/cornell-notes/build/cornhell-37b881e150badb60bb90a0054b1665ba.png" class="h-9" height="2.25rem"/></div><span class="text-md sm:text-xl tracking-tight sm:mr-5 sr-only">Made with MyST</span></a></div><div class="flex items-center flex-grow w-auto"><div class="flex-grow hidden text-md lg:block"></div><div class="flex-grow block"></div><button type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R74op:" data-state="closed" class="flex items-center h-10 aspect-square sm:w-64 text-left text-gray-400 border border-gray-300 dark:border-gray-600 rounded-lg bg-gray-50 dark:bg-gray-700 hover:ring-blue-500 dark:hover:ring-blue-500 hover:border-blue-500 dark:hover:border-blue-500"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="p-2.5 h-10 w-10 aspect-square"><path fill-rule="evenodd" d="M10.5 3.75a6.75 6.75 0 1 0 0 13.5 6.75 6.75 0 0 0 0-13.5ZM2.25 10.5a8.25 8.25 0 1 1 14.59 5.28l4.69 4.69a.75.75 0 1 1-1.06 1.06l-4.69-4.69A8.25 8.25 0 0 1 2.25 10.5Z" clip-rule="evenodd"></path></svg><span class="hidden sm:block grow">Search</span><div aria-hidden="true" class="items-center hidden mx-1 font-mono text-sm text-gray-400 sm:flex gap-x-1"><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none hide-mac">CTRL</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none show-mac">⌘</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none ">K</kbd><script>
;(() => {
const script = document.currentScript;
const root = script.parentElement;

const isMac = /mac/i.test(
      window.navigator.userAgentData?.platform ?? window.navigator.userAgent,
    );
root.querySelectorAll(".hide-mac").forEach(node => {node.classList.add(isMac ? "hidden" : "block")});
root.querySelectorAll(".show-mac").forEach(node => {node.classList.add(!isMac ? "hidden" : "block")});
})()</script></div></button><button class="theme rounded-full aspect-square border border-stone-700 dark:border-white hover:bg-neutral-100 border-solid overflow-hidden text-stone-700 dark:text-white hover:text-stone-500 dark:hover:text-neutral-800 w-8 h-8 mx-3" title="Toggle theme between light and dark mode" aria-label="Toggle theme between light and dark mode"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="h-full w-full p-0.5 hidden dark:block"><path fill-rule="evenodd" d="M9.528 1.718a.75.75 0 0 1 .162.819A8.97 8.97 0 0 0 9 6a9 9 0 0 0 9 9 8.97 8.97 0 0 0 3.463-.69.75.75 0 0 1 .981.98 10.503 10.503 0 0 1-9.694 6.46c-5.799 0-10.5-4.7-10.5-10.5 0-4.368 2.667-8.112 6.46-9.694a.75.75 0 0 1 .818.162Z" clip-rule="evenodd"></path></svg><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-full w-full p-0.5 dark:hidden"><path stroke-linecap="round" stroke-linejoin="round" d="M12 3v2.25m6.364.386-1.591 1.591M21 12h-2.25m-.386 6.364-1.591-1.591M12 18.75V21m-4.773-4.227-1.591 1.591M5.25 12H3m4.227-4.773L5.636 5.636M15.75 12a3.75 3.75 0 1 1-7.5 0 3.75 3.75 0 0 1 7.5 0Z"></path></svg></button><div class="block sm:hidden"></div><div class="hidden sm:block"></div></div></nav></div><div class="fixed xl:article-grid grid-gap xl:w-screen xl:pointer-events-none overflow-auto max-xl:min-w-[300px] hidden z-10" style="top:60px"><div class="pointer-events-auto xl:col-margin-left flex-col overflow-hidden hidden xl:flex"><div class="flex-grow py-6 overflow-y-auto primary-scrollbar"><nav aria-label="Navigation" class="overflow-y-hidden transition-opacity ml-3 xl:ml-0 mr-3 max-w-[350px] lg:hidden"><div class="w-full px-1 dark:text-white font-medium"></div></nav><div class="my-3 border-b-2 lg:hidden"></div><nav aria-label="Table of Contents" class="flex-grow overflow-y-hidden transition-opacity ml-3 xl:ml-0 mr-3 max-w-[350px]"><div class="w-full px-1 dark:text-white"><a title="Incomplete CS Notes @ Cornell" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30 font-bold" href="/cornell-notes/">Incomplete CS Notes @ Cornell</a><a title="INFO1998 Intro to Machine Learning" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/cornell-notes/2020-10-02-info1998-intro-to-machine-learning">INFO1998 Intro to Machine Learning</a><a title="CS2024 C++ Programming" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/cornell-notes/2020-09-07-cs2024-c-programming">CS2024 C++ Programming</a><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="CS2112 Object-Oriented Design (Honors)" class="block break-words rounded py-2 grow cursor-pointer">CS2112 Object-Oriented Design (Honors)</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R16p8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R16p8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="CS3110 Functional Programming" class="block break-words rounded py-2 grow cursor-pointer">CS3110 Functional Programming</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R1ep8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R1ep8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="CS4780 Intro to Machine Learning" class="block break-words rounded py-2 grow cursor-pointer">CS4780 Intro to Machine Learning</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R1mp8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R1mp8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="CS4787 Principles of Large-Scale Machine Learning" class="block break-words rounded py-2 grow cursor-pointer">CS4787 Principles of Large-Scale Machine Learning</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R1up8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R1up8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><a title="CS4820 Intro to Analysis of Algorithms" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/cornell-notes/2020-10-13-cs4820-intro-to-analysis-of-algorithms">CS4820 Intro to Analysis of Algorithms</a><a title="ORIE4350 Game Theory" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/cornell-notes/2022-02-08-orie4350-game-theory">ORIE4350 Game Theory</a></div></nav></div><div class="flex-none py-6 transition-all duration-700 translate-y-6 opacity-0"><a class="flex mx-auto text-gray-700 w-fit hover:text-blue-700 dark:text-gray-200 dark:hover:text-blue-400" href="https://mystmd.org/made-with-myst" target="_blank" rel="noreferrer"><svg style="width:24px;height:24px" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100" stroke="none"><g id="icon"><path fill="currentColor" d="M23.8,54.8v-3.6l4.7-0.8V17.5l-4.7-0.8V13H36l13.4,31.7h0.2l13-31.7h12.6v3.6l-4.7,0.8v32.9l4.7,0.8v3.6h-15
          v-3.6l4.9-0.8V20.8H65L51.4,53.3h-3.8l-14-32.5h-0.1l0.2,17.4v12.1l5,0.8v3.6H23.8z"></path><path fill="#F37726" d="M47,86.9c0-5.9-3.4-8.8-10.1-8.8h-8.4c-5.2,0-9.4-1.3-12.5-3.8c-3.1-2.5-5.4-6.2-6.8-11l4.8-1.6
          c1.8,5.6,6.4,8.6,13.8,8.8h9.2c6.4,0,10.8,2.5,13.1,7.5c2.3-5,6.7-7.5,13.1-7.5h8.4c7.8,0,12.7-2.9,14.6-8.7l4.8,1.6
          c-1.4,4.9-3.6,8.6-6.8,11.1c-3.1,2.5-7.3,3.7-12.4,3.8H63c-6.7,0-10,2.9-10,8.8"></path></g></svg><span class="self-center ml-2 text-sm">Made with MyST</span></a></div></div></div><main class="article-grid grid-gap"><article class="article-grid subgrid-gap col-screen article content"><div class="hidden"></div><div id="skip-to-frontmatter" aria-label="article frontmatter" class="mb-8 pt-9"><div class="flex items-center h-6 mb-5 text-sm font-light"><div class="flex-grow"></div></div><h1 class="mb-0">INFO1998 Intro to Machine Learning</h1><header class="mt-4 not-prose"><div class="grid grid-cols-1 sm:grid-cols-2 gap-y-1"><div><span class="font-semibold text-sm"><button class="focus:shadow-[0_0_0_2px] focus:shadow-black outline-none hover:underline" aria-label="Author Details" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R2t8top:" data-state="closed">Yao Lirong</button></span></div><div class="text-sm"><div>Cornell University<!-- --> </div></div></div></header><div class="flex mt-2 text-sm font-light"><time dateTime="2020-10-02" class="">October 2, 2020</time></div></div><div class="block my-10 lg:sticky lg:z-10 lg:h-0 lg:pt-0 lg:my-0 lg:ml-10 lg:col-margin-right" style="top:60px"><nav></nav></div><div id="skip-to-article"></div><p>The goal of this course is to provide you with a high-level exposure to a wide range of Data Science techniques and Machine Learning models. From the basics of getting your Jupyter environment setup, to manipulating  and visualizing data, to building supervised and unsupervised models,  this class aims to give you the base intuition and skillset to continue  developing and working on ML projects. We hope you exit the course with  an understanding of how models and optimization techniques work, as well as have the confidence and tools to solve future problems on your own.</p><h2 id="lec2-data-manipulation" class="relative group"><span class="heading-text">Lec2 Data Manipulation</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#lec2-data-manipulation" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><h3 id="introduction-to-pandas" class="relative group"><span class="heading-text">Introduction to Pandas</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#introduction-to-pandas" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><ul><li><code>Series</code>: one dimensional array</li><li><code>DataFrame</code>: 2-D table<ul><li>Filtering DataFrames: <code>loc</code></li><li>Cleaning-Up DataFrames: <code>df.dropna()</code>, <code>df[df[&#x27;Open&#x27;].notnull()]</code> (These two methods both return a new DataFrame instead of modifying the existed one)</li><li>View DataFrames: <code>head</code>, <code>tail</code>, ...</li><li>Summary Statistics: <code>mean</code>, <code>median</code>, ... <code>describe</code></li></ul></li></ul><h3 id="dealing-with-missing-data" class="relative group"><span class="heading-text">Dealing with missing data</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#dealing-with-missing-data" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><ul><li><p>Fill in some random info of our choice:</p><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">#if we there is no record about which cabin he is in, we assume he is on the Top Deck
df[&#x27;Cabin&#x27;]=df[&#x27;Cabin&#x27;].fillna(&#x27;Top Deck&#x27;) </code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div></li><li><p>Using summary statistics: fill missing entries with median or mean</p><p>works well with small set</p></li><li><p>Use regression and clustering: will be covered later</p></li></ul><h2 id="lec3-data-visualization" class="relative group"><span class="heading-text">Lec3 Data Visualization</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#lec3-data-visualization" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><h3 id="types-of-graphs" class="relative group"><span class="heading-text">Types of Graphs</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#types-of-graphs" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><ul><li>Heatmap</li><li>Correlation Plots</li></ul><h3 id="coloring-graphs" class="relative group"><span class="heading-text">Coloring Graphs</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#coloring-graphs" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p><code>plt.scatter(Longitude, Latitude, c=Temp.values.ravel(),cmap=plt.cm.OrRd)</code> color a scattered plot based on values of <code>Temp</code> with color scheme <code>cm.OrRd</code>. Find more color schemes from <a target="_blank" rel="noreferrer" href="https://matplotlib.org/3.1.0/tutorials/colors/colormaps.html" class="">matplotlib manual</a>.</p><h2 id="lec4-linear-regression" class="relative group"><span class="heading-text">Lec4 Linear Regression</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#lec4-linear-regression" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><h3 id="preparing-data" class="relative group"><span class="heading-text">Preparing Data</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#preparing-data" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
# X must be a table (in case there are multiple x in y = a1*x1 + a2*x2 + ... + k)
X = data[[&#x27;cost&#x27;,&#x27;compl_4&#x27;]] 
# Y must be one column
Y = data[&#x27;median_earnings&#x27;] 

from sklearn.model_selection import train_test_split
# test is 20% of all data
x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><h3 id="predicting-and-fitting" class="relative group"><span class="heading-text">Predicting and Fitting</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#predicting-and-fitting" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># creates Linear Regression model 
LR = LinearRegression()
# note LR is an object by calling fit, we set all of its coefficients
LR.fit(x_train, y_train)
# predict() returns the predicted value
y_predicted = LR.predict(x_test)
# score(x,y&#x27;) first computes the predicted value y based on x and our model, then compare it with y&#x27;
score = LR.score(x_test,y_test)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><h3 id="describing-the-model" class="relative group"><span class="heading-text">Describing the Model</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#describing-the-model" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># Gives a comprehensive view of Y = a1*x1 + a2*x2 + ... + k
LR?

# coefficients of x (a1, a2, ...)
LR.coef_

# intercept k
LR.intercept_</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><h2 id="lec5-measuring-models-accuracy" class="relative group"><span class="heading-text">Lec5 Measuring Model’s Accuracy</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#lec5-measuring-models-accuracy" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>When determining accuracy, usually want to compare our model to a baseline. Therefore, instead of comparing our model’s prediction to each specific <code>y</code> value, we compare it with the mean <code>y</code> value.</p><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">from sklearn.metrics import mean_squared_error
celcius_MSE = mean_squared_error(y_test, celcius_predictions)

test_goal_mean = y_test.mean()
baseline = np.full((len(celcius_predictions),), test_goal_mean)
baseline_MSE = mean_squared_error(baseline, celcius_predictions)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><ul><li>overfitting: too specific to the data given, doesn’t predict any other data</li><li>underfitting: no matter what data you use to train this model, it gives the same curve, so it doesn’t have prediction power either because it doesn’t show any pattern of the data.</li></ul><h2 id="lec6-classifiers" class="relative group"><span class="heading-text">Lec6 Classifiers</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#lec6-classifiers" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>Linear regression is used to predict the value of a continuous variable. Classifiers are used to predict <strong>categorical or binary variables</strong>.</p><h3 id="knn" class="relative group"><span class="heading-text">KNN</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#knn" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
x_train, x_test, y_train, y_test = train_test_split(X,Y, test_size=0.2)

k = 10
model = KNeighborsClassifier(k) # specify k nearest elements
model.fit(x_train,y_train)
predictions = model.predict(x_test)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><h2 id="lec7-other-supervised-learning-models" class="relative group"><span class="heading-text">Lec7 Other Supervised Learning Models</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#lec7-other-supervised-learning-models" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><h3 id="decision-trees" class="relative group"><span class="heading-text">Decision Trees</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#decision-trees" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">from sklearn import tree
from sklearn.tree import DecisionTreeClassifier
model = tree.DecisionTreeClassifier(max_depth=5)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><p>How to reduce overfitting?</p><ul><li>Reduce levels of trees</li><li>Train multiple decision trees (maybe one for each training data) and take its average as final result</li></ul><h3 id="logistic-regression" class="relative group"><span class="heading-text">Logistic Regression</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#logistic-regression" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>Value always between 0 and 1. Accept if value higher than threshold, reject if lower.</p><h3 id="k-fold-cross-validation" class="relative group"><span class="heading-text">K-fold Cross Validation</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#k-fold-cross-validation" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>Rather than doing test-train split only once, we do it k times: First separate our sample into k pieces and each time we take one of them as test set, the others as training set. Use <code>from sklearn.model_selection import KFold</code> to achieve this. Calculate a score for each of the split and take its average as the final score. This score is usually closer to real errors.</p><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">from sklearn.model_selection import KFold
from sklearn.metrics import mean_squared_error, accuracy_score

incX = inc_data[[&#x27;education.num&#x27;]]
incY = inc_data[&#x27;income&#x27;]

kf = KFold(n_splits = 5)
accuracy = 0
for train_index, test_index in kf.split(incX):
    X_train = incX.iloc[train_index]
    Y_train = incY.iloc[train_index]
    X_test = incX.iloc[test_index]
    Y_test = incY.iloc[test_index]
    
    # best_depth 是我们前一题找到的使分最高的 depth level of decision tree
    model = tree.DecisionTreeClassifier (max_depth = best_depth)
    model.fit(X_train, Y_train)
    pred_test = model.predict(X_test)
    accuracy += accuracy_score(Y_test, pred_test)
    
accuracy /= 5
print(accuracy)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><h2 id="lec9-unsupervised-learning" class="relative group"><span class="heading-text">Lec9 Unsupervised Learning</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#lec9-unsupervised-learning" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><ul><li>Supervised Learning: The desired solution (target) is also included in the dataset</li><li>Unsupervised Learning: The training data is unlabeled and algorithm tries to learn by itself</li></ul><h3 id="hierarchical-clustering" class="relative group"><span class="heading-text">Hierarchical Clustering</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#hierarchical-clustering" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>Hierarchical clustering groups observations into multiple levels of  sets; the top-level set includes all of the data, and the bottom-level  sets contain individual observations. The levels in between contain sets of observations with similar features.</p><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">from sklearn.preprocessing import StandardScaler
from scipy.cluster.hierarchy import dendrogram, linkage
from matplotlib import pyplot as plt

# Standardize features by removing the mean and scaling to unit variance
data = StandardScaler().fit_transform(data)
# build our model from data
clust = linkage(data) 
# draw the dendrogram visulization
dendrogram(clust)
plt.show()</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><h3 id="k-means-clustering" class="relative group"><span class="heading-text">K-Means Clustering</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#k-means-clustering" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>We want to cluster the data into k groups. We first randomly choose k points in this dataset. Then we assign other data points to the group they are closest to. After assigning all data points to some group, we recompute the center of each group by taking the means of all points in that group. Repeat this process until no points change group assignment after one iteration.</p><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">from sklearn import cluster
k = 3
kmeans = cluster.KMeans(n_clusters = k) #cluster into k groups
kmeans.fit(data)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div></div><div class="flex pt-10 mb-10 space-x-4"><a class="flex-1 block p-4 font-normal text-gray-600 no-underline border border-gray-200 rounded shadow-sm group hover:border-blue-600 dark:hover:border-blue-400 hover:text-blue-600 dark:hover:text-blue-400 dark:text-gray-100 dark:border-gray-500 hover:shadow-lg dark:shadow-neutral-700" href="/cornell-notes/"><div class="flex h-full align-middle"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="self-center transition-transform group-hover:-translate-x-1 shrink-0"><path stroke-linecap="round" stroke-linejoin="round" d="M10.5 19.5 3 12m0 0 7.5-7.5M3 12h18"></path></svg><div class="flex-grow text-right"><div class="text-xs text-gray-500 dark:text-gray-400">Incomplete CS Notes @ Cornell</div>Incomplete CS Notes @ Cornell</div></div></a><a class="flex-1 block p-4 font-normal text-gray-600 no-underline border border-gray-200 rounded shadow-sm group hover:border-blue-600 dark:hover:border-blue-400 hover:text-blue-600 dark:hover:text-blue-400 dark:text-gray-100 dark:border-gray-500 hover:shadow-lg dark:shadow-neutral-700" href="/cornell-notes/2020-09-07-cs2024-c-programming"><div class="flex h-full align-middle"><div class="flex-grow"><div class="text-xs text-gray-500 dark:text-gray-400">Incomplete CS Notes @ Cornell</div>CS2024 C++ Programming</div><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="self-center transition-transform group-hover:translate-x-1 shrink-0"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 4.5 21 12m0 0-7.5 7.5M21 12H3"></path></svg></div></a></div></article></main><script>((a,d)=>{if(!window.history.state||!window.history.state.key){let h=Math.random().toString(32).slice(2);window.history.replaceState({key:h},"")}try{let f=JSON.parse(sessionStorage.getItem(a)||"{}")[d||window.history.state.key];typeof f=="number"&&window.scrollTo(0,f)}catch(h){console.error(h),sessionStorage.removeItem(a)}})("positions", null)</script><link rel="modulepreload" href="/cornell-notes/build/entry.client-UNPC4GT3.js"/><link rel="modulepreload" href="/cornell-notes/build/_shared/chunk-OCTKKCIL.js"/><link rel="modulepreload" href="/cornell-notes/build/_shared/chunk-UAI5KRM7.js"/><link rel="modulepreload" href="/cornell-notes/build/_shared/chunk-2NH4LW52.js"/><link rel="modulepreload" href="/cornell-notes/build/_shared/chunk-L6RR67CB.js"/><link rel="modulepreload" href="/cornell-notes/build/_shared/chunk-HBJK6BW3.js"/><link rel="modulepreload" href="/cornell-notes/build/_shared/chunk-HYMQ7M2K.js"/><link rel="modulepreload" href="/cornell-notes/build/_shared/chunk-OHOXABTA.js"/><link rel="modulepreload" href="/cornell-notes/build/_shared/chunk-OCWQY3HK.js"/><link rel="modulepreload" href="/cornell-notes/build/_shared/chunk-C7FW3E47.js"/><link rel="modulepreload" href="/cornell-notes/build/_shared/chunk-3CVK3PYF.js"/><link rel="modulepreload" href="/cornell-notes/build/_shared/chunk-J6FHCSRC.js"/><link rel="modulepreload" href="/cornell-notes/build/_shared/chunk-ND43KHSX.js"/><link rel="modulepreload" href="/cornell-notes/build/_shared/chunk-GUCIBHGO.js"/><link rel="modulepreload" href="/cornell-notes/build/root-LY5YATWI.js"/><link rel="modulepreload" href="/cornell-notes/build/_shared/chunk-KBQ63U4V.js"/><link rel="modulepreload" href="/cornell-notes/build/routes/$-RAODST7L.js"/><script>window.__remixContext = {"url":"/2020-10-02-info1998-intro-to-machine-learning","state":{"loaderData":{"root":{"config":{"version":2,"myst":"1.6.0","options":{"favicon":"/cornell-notes/build/favicon-615119cb910b2b2604fa7c8e61a4cffe.ico","logo":"/cornell-notes/build/cornhell-37b881e150badb60bb90a0054b1665ba.png"},"nav":[],"actions":[],"projects":[{"title":"Incomplete CS Notes @ Cornell","description":"This is a complete collection of course notes I've taken when studying CS at Cornell University","authors":[{"nameParsed":{"literal":"Yao Lirong","given":"Yao","family":"Lirong"},"name":"Yao Lirong","affiliations":["Cornell University"],"url":"https://yao-lirong.github.io","linkedin":"https://www.linkedin.com/in/yao-lirong/","id":"contributors-myst-generated-uid-0"}],"keywords":["Cornell","CS","Yao Lirong"],"affiliations":[{"id":"Cornell University","name":"Cornell University"}],"id":"dbd3e509-63c9-4982-a7c3-5cf505dc3c02","toc":[{"file":"index.md"},{"file":"2020-10-02-INFO1998-Intro-to-Machine-Learning.md"},{"file":"2020-09-07-CS2024-C++-Programming.md"},{"children":[{"file":"CS2112/2019-09-24-Generics.md"},{"file":"CS2112/2019-09-30-Value-Representation,-Hashing,-and-Generics.md"},{"file":"CS2112/2019-10-08-Parsing.md"},{"file":"CS2112/2019-10-17-Designing-and-documenting-interfaces-and-implementations.md"},{"file":"CS2112/2019-10-24-Design-Pattern.md"},{"file":"CS2112/2019-10-29 Event Handlers.md"},{"file":"CS2112/2019-11-07-Concurrency.md"},{"file":"CS2112/2019-11-12-synchronization.md"},{"file":"CS2112/2019-11-19-Graph-Traversal.md"},{"file":"CS2112/2019-11-20-Graph-(Recitation).md"},{"file":"CS2112/2019-11-21-shortest-path-algorithm.md"},{"file":"CS2112/2019-11-23-Android-Basics-User-Interface.md"},{"file":"CS2112/2019-11-26-Priority-Queue-and-Heap.md"},{"file":"CS2112/2019-12-05-Problem-Analysis.md"}],"title":"CS2112 Object-Oriented Design (Honors)"},{"children":[{"file":"CS3110/2020-01-28-Functions.md"},{"file":"CS3110/2020-01-30-Standard-Data-Types.md"},{"file":"CS3110/2020-02-04-Advanced-Data-Types.md"},{"file":"CS3110/2020-02-06-Higher-Order-Functions.md"},{"file":"CS3110/2020-02-11-Modules.md"},{"file":"CS3110/2020-02-13-Code-Reuse-with-Modules.md"},{"file":"CS3110/2020-02-18-Specifications.md"},{"file":"CS3110/2020-03-03-Mutability.md"},{"file":"CS3110/2020-04-06-Red-Black-Tree.md"},{"file":"CS3110/2020-04-09-Interpreter.md"},{"file":"CS3110/2020-04-14-The-Substitution-Model.md"},{"file":"CS3110/2020-04-16-The-Environment-Model.md"}],"title":"CS3110 Functional Programming"},{"children":[{"file":"CS4780/2021-08-31-Machine-Learning-Basics.md"},{"file":"CS4780/2021-09-02-K-Nearest-Neighbors.md"},{"file":"CS4780/2021-09-07-K-means-clustering.md"},{"file":"CS4780/2021-09-09-Principal-Component-Analysis.md"},{"file":"CS4780/2021-09-14-The-Perceptron.md"},{"file":"CS4780/2021-09-16-MLE-and-MAP.md"},{"file":"CS4780/2021-09-21-Naive-Bayes.md"},{"file":"CS4780/2021-09-28-Logistic-Regression.md"},{"file":"CS4780/2021-09-30-Gradient-Descent.md"},{"file":"CS4780/2021-10-05-Important-Distributions-and-Linear-Regression.md"},{"file":"CS4780/2021-10-07-SVM---Support-Vector-Machine.md"},{"file":"CS4780/2021-10-14-Empirical-Risk-Minimization.md"},{"file":"CS4780/2021-10-19-Midterm-Review.md"},{"file":"CS4780/2021-10-26-Bias-Variance-Tradeoff.md"},{"file":"CS4780/2021-10-28-Model-Selection-Tricks.md"},{"file":"CS4780/2021-11-02-Kernels.md"},{"file":"CS4780/2021-11-04-More-on-Kernels.md"},{"file":"CS4780/2021-11-09-Decision-Tree.md"},{"file":"CS4780/2021-11-16-Bagging.md"},{"file":"CS4780/2021-11-18-Boosting.md"}],"title":"CS4780 Intro to Machine Learning"},{"children":[{"file":"CS4787/2022-08-22-Introduction.md"},{"file":"CS4787/2022-08-24-Linear-Algebra-and-NumPy.md"},{"file":"CS4787/2022-08-29-Automatic-Differentiation.md"},{"file":"CS4787/2022-08-31-Back-Propagation.md"},{"file":"CS4787/2022-09-12-Gradient-Descent.md"},{"file":"CS4787/2022-09-14-Gradient-Descent-and-Convexity.md"},{"file":"CS4787/2022-09-19-Stochastic-Gradient-Descent.md"},{"file":"CS4787/2022-09-21-Stochastic-Gradient-Descent-Improved.md"},{"file":"CS4787/2022-09-26-SGD-with-Momentum.md"},{"file":"CS4787/2022-09-28-Preconditioning-and-Element-Specific-Learning-Rate.md"},{"file":"CS4787/2022-10-03-Adaptive-Learning-Rate-and-Variance-Reduction.md"},{"file":"CS4787/2022-10-05-Sparsity-and-Dimension-Reduction.md"},{"file":"CS4787/2022-10-12-Neural-Network-Review.md"},{"file":"CS4787/2022-10-17-Accelerate-DNN-Training.md"},{"file":"CS4787/2022-10-19-Beyond-supervised-learning.md"},{"file":"CS4787/2022-10-24-Attention,-Transformers,-and-Transfer-Learning.md"}],"title":"CS4787 Principles of Large-Scale Machine Learning"},{"file":"2020-10-13-CS4820-Intro-to-Analysis-of-Algorithms.md"},{"file":"2022-02-08-ORIE4350-Game-Theory.md"}],"thumbnail":"/cornell-notes/build/cornhell-37b881e150badb60bb90a0054b1665ba.png","exports":[],"bibliography":[],"index":"index","pages":[{"slug":"2020-10-02-info1998-intro-to-machine-learning","title":"INFO1998 Intro to Machine Learning","description":"","date":"2020-10-02","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20FA","Python"],"level":1},{"slug":"2020-09-07-cs2024-c-programming","title":"CS2024 C++ Programming","description":"","date":"2020-09-07","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","CS2024","20FA"],"level":1},{"level":1,"title":"CS2112 Object-Oriented Design (Honors)"},{"slug":"2019-09-24-generics","title":"Generics","description":"","date":"2019-09-24","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","19FA","CS2112"],"level":2},{"slug":"2019-09-30-value-representation-hashing-and-generi","title":"Value Representation, Hashing, and Generics","description":"","date":"2019-09-30","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","FA19","CS2112"],"level":2},{"slug":"2019-10-08-parsing","title":"Parsing","description":"","date":"2019-10-08","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","19FA","CS2112"],"level":2},{"slug":"2019-10-17-designing-and-documenting-interfaces-an","title":"Designing and documenting interfaces and implementations","description":"","date":"2019-10-17","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","19FA","CS2112"],"level":2},{"slug":"2019-10-24-design-pattern","title":"Design Pattern","description":"","date":"2019-10-24","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","19FA","CS2112"],"level":2},{"slug":"2019-10-29-event-handlers","title":"Building GUI","description":"","date":"2019-10-29","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","19FA","CS2112"],"level":2},{"slug":"2019-11-07-concurrency","title":"Concurrency","description":"","date":"2019-11-07","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","19FA","CS2112"],"level":2},{"slug":"2019-11-12-synchronization","title":"Synchronization","description":"","date":"2019-11-12","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","19FA","CS2112"],"level":2},{"slug":"2019-11-19-graph-traversal","title":"Graph Traversal","description":"","date":"2019-11-19","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","19FA","CS2112"],"level":2},{"slug":"2019-11-20-graph-recitation","title":"Graph (Recitation)","description":"","date":"2019-11-20","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","19FA","CS2112"],"level":2},{"slug":"2019-11-21-shortest-path-algorithm","title":"shortest path algorithm","description":"","date":"2019-11-21","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","CS2112"],"level":2},{"slug":"2019-11-23-android-basics-user-interface","title":"Udacity: Android Basics","description":"","date":"2019-11-23","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Android"],"level":2},{"slug":"2019-11-26-priority-queue-and-heap","title":"Priority Queue and Heap","description":"","date":"2019-11-26","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","CS2112"],"level":2},{"slug":"2019-12-05-problem-analysis","title":"Problem Analysis","description":"","date":"2019-12-05","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","CS2112"],"level":2},{"level":1,"title":"CS3110 Functional Programming"},{"slug":"2020-01-28-functions","title":"Functions","description":"","date":"2020-01-28","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"slug":"2020-01-30-standard-data-types","title":"Standard Data Types","description":"","date":"2020-01-30","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"slug":"2020-02-04-advanced-data-types","title":"Advanced Data Types","description":"","date":"2020-02-04","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"slug":"2020-02-06-higher-order-functions","title":"Higher-Order Functions","description":"","date":"2020-02-06","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"slug":"2020-02-11-modules","title":"Modules","description":"","date":"2020-02-11","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"slug":"2020-02-13-code-reuse-with-modules","title":"Code Reuse with Modules","description":"","date":"2020-02-13","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"slug":"2020-02-18-specifications","title":"Specifications","description":"","date":"2020-02-18","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"slug":"2020-03-03-mutability","title":"Mutability","description":"","date":"2020-03-03","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"slug":"2020-04-06-red-black-tree","title":"Red Black Tree","description":"","date":"2020-04-06","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","CS3110","20SP"],"level":2},{"slug":"2020-04-09-interpreter","title":"Interpreter","description":"","date":"2020-04-09","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"slug":"2020-04-14-the-substitution-model","title":"The Substitution Model","description":"","date":"2020-04-14","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"slug":"2020-04-16-the-environment-model","title":"The Environment Model","description":"","date":"2020-04-16","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"level":1,"title":"CS4780 Intro to Machine Learning"},{"slug":"2021-08-31-machine-learning-basics","title":"Machine Learning Basics","description":"","date":"2021-08-31","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS"],"level":2},{"slug":"2021-09-02-k-nearest-neighbors","title":"K-Nearest Neighbors","description":"","date":"2021-09-02","thumbnail":"/cornell-notes/build/d2d32ed7f030408c4751b4082cc4c4fb.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-09-07-k-means-clustering","title":"K-means clustering","description":"","date":"2021-09-07","thumbnail":"/cornell-notes/build/2b624c0dfc4541e6702d7d03a35846a3.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-09-09-principal-component-analysis","title":"Principal Component Analysis","description":"","date":"2021-09-09","thumbnail":"/cornell-notes/build/0f82a0d8a1b909f3be9ff331e1e605e3.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-09-14-the-perceptron","title":"The Perceptron","description":"","date":"2021-09-14","thumbnail":"/cornell-notes/build/0561dbd9a0937d3d1decc2a2e9d7a150.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-09-16-mle-and-map","title":"MLE and MAP","description":"","date":"2021-09-16","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-09-21-naive-bayes","title":"Naive Bayes","description":"","date":"2021-09-21","thumbnail":"/cornell-notes/build/1dec3195698f490f89eb8383ef29b8c8.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-09-28-logistic-regression","title":"Logistic Regression","description":"","date":"2021-09-28","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-09-30-gradient-descent","title":"Gradient Descent","description":"","date":"2021-09-30","thumbnail":"/cornell-notes/build/e3d52da6368f919deb4783b786520acd.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-10-05-important-distributions-and-linear-regr","title":"Important Distributions and Linear Regression","description":"","date":"2021-10-05","thumbnail":"/cornell-notes/build/023faa064932bbe5ec11298e7cbdbdbd.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-10-07-svm-support-vector-machine","title":"SVM - Support Vector Machine","description":"","date":"2021-10-07","thumbnail":"/cornell-notes/build/41379864e80001dd60125813623c4915.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-10-14-empirical-risk-minimization","title":"Empirical Risk Minimization","description":"","date":"2021-10-14","thumbnail":"/cornell-notes/build/f9e37f639bf7ed7d0e0daf5d55dee992.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-10-19-midterm-review","title":"Midterm Review","description":"","date":"2021-10-19","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-10-26-bias-variance-tradeoff","title":"Bias-Variance Tradeoff","description":"","date":"2021-10-26","thumbnail":"/cornell-notes/build/92f79954ba3e60170a726689263cc46c.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-10-28-model-selection-tricks","title":"Model Selection Tricks","description":"","date":"2021-10-28","thumbnail":"/cornell-notes/build/643c4fcd86a736a95208145a3a53f8ee.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-11-02-kernels","title":"Kernels","description":"","date":"2021-11-02","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-11-04-more-on-kernels","title":"More on Kernels","description":"","date":"2021-11-04","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-11-09-decision-tree","title":"Decision Tree","description":"","date":"2021-11-09","thumbnail":"/cornell-notes/build/2f6b3cd8046659d873cef1793b421adf.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-11-16-bagging","title":"Bagging","description":"","date":"2021-11-16","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-11-18-boosting","title":"Boosting","description":"","date":"2021-11-18","thumbnail":"/cornell-notes/build/315b0684d85fc252232fdf8cba2a9c87.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"CS4787 Principles of Large-Scale Machine Learning"},{"slug":"2022-08-22-introduction","title":"Introduction","description":"","date":"2022-08-22","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-08-24-linear-algebra-and-numpy","title":"Linear Algebra and NumPy","description":"","date":"2022-08-24","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-08-29-automatic-differentiation","title":"Automatic Differentiation","description":"","date":"2022-08-29","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-08-31-back-propagation","title":"Back Propagation","description":"","date":"2022-08-31","thumbnail":"/cornell-notes/build/9a793e5d3b94eacefaeb4ada8b427898.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-09-12-gradient-descent","title":"Gradient Descent","description":"","date":"2022-09-12","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-09-14-gradient-descent-and-convexity","title":"Gradient Descent and Convexity","description":"","date":"2022-09-14","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-09-19-stochastic-gradient-descent","title":"Stochastic Gradient Descent","description":"","date":"2022-09-19","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-09-21-stochastic-gradient-descent-improved","title":"Stochastic Gradient Descent Improved","description":"","date":"2022-09-21","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-09-26-sgd-with-momentum","title":"SGD with Momentum","description":"","date":"2022-09-26","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-09-28-preconditioning-and-element-specific-le","title":"Preconditioning and Element Specific Learning Rate","description":"","date":"2022-09-28","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-10-03-adaptive-learning-rate-and-variance-red","title":"Adaptive Learning Rate and Variance Reduction","description":"","date":"2022-10-03","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-10-05-sparsity-and-dimension-reduction","title":"Sparsity and Dimension Reduction","description":"","date":"2022-10-05","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-10-12-neural-network-review","title":"Neural Network Review","description":"","date":"2022-10-12","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-10-17-accelerate-dnn-training","title":"Accelerate DNN Training","description":"","date":"2022-10-17","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-10-19-beyond-supervised-learning","title":"Beyond supervised learning","description":"","date":"2022-10-19","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-10-24-attention-transformers-and-transfer-lea","title":"Attention, Transformers, and Transfer Learning","description":"","date":"2022-10-24","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2020-10-13-cs4820-intro-to-analysis-of-algorithms","title":"CS4820 Intro to Analysis of Algorithms","description":"","date":"2020-10-13","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","CS4820"],"level":1},{"slug":"2022-02-08-orie4350-game-theory","title":"ORIE4350 Game Theory","description":"","date":"2022-02-08","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1}]}]},"CONTENT_CDN_PORT":"3100","MODE":"static","BASE_URL":"/cornell-notes"},"routes/$":{"config":{"version":2,"myst":"1.6.0","options":{"favicon":"/cornell-notes/build/favicon-615119cb910b2b2604fa7c8e61a4cffe.ico","logo":"/cornell-notes/build/cornhell-37b881e150badb60bb90a0054b1665ba.png"},"nav":[],"actions":[],"projects":[{"title":"Incomplete CS Notes @ Cornell","description":"This is a complete collection of course notes I've taken when studying CS at Cornell University","authors":[{"nameParsed":{"literal":"Yao Lirong","given":"Yao","family":"Lirong"},"name":"Yao Lirong","affiliations":["Cornell University"],"url":"https://yao-lirong.github.io","linkedin":"https://www.linkedin.com/in/yao-lirong/","id":"contributors-myst-generated-uid-0"}],"keywords":["Cornell","CS","Yao Lirong"],"affiliations":[{"id":"Cornell University","name":"Cornell University"}],"id":"dbd3e509-63c9-4982-a7c3-5cf505dc3c02","toc":[{"file":"index.md"},{"file":"2020-10-02-INFO1998-Intro-to-Machine-Learning.md"},{"file":"2020-09-07-CS2024-C++-Programming.md"},{"children":[{"file":"CS2112/2019-09-24-Generics.md"},{"file":"CS2112/2019-09-30-Value-Representation,-Hashing,-and-Generics.md"},{"file":"CS2112/2019-10-08-Parsing.md"},{"file":"CS2112/2019-10-17-Designing-and-documenting-interfaces-and-implementations.md"},{"file":"CS2112/2019-10-24-Design-Pattern.md"},{"file":"CS2112/2019-10-29 Event Handlers.md"},{"file":"CS2112/2019-11-07-Concurrency.md"},{"file":"CS2112/2019-11-12-synchronization.md"},{"file":"CS2112/2019-11-19-Graph-Traversal.md"},{"file":"CS2112/2019-11-20-Graph-(Recitation).md"},{"file":"CS2112/2019-11-21-shortest-path-algorithm.md"},{"file":"CS2112/2019-11-23-Android-Basics-User-Interface.md"},{"file":"CS2112/2019-11-26-Priority-Queue-and-Heap.md"},{"file":"CS2112/2019-12-05-Problem-Analysis.md"}],"title":"CS2112 Object-Oriented Design (Honors)"},{"children":[{"file":"CS3110/2020-01-28-Functions.md"},{"file":"CS3110/2020-01-30-Standard-Data-Types.md"},{"file":"CS3110/2020-02-04-Advanced-Data-Types.md"},{"file":"CS3110/2020-02-06-Higher-Order-Functions.md"},{"file":"CS3110/2020-02-11-Modules.md"},{"file":"CS3110/2020-02-13-Code-Reuse-with-Modules.md"},{"file":"CS3110/2020-02-18-Specifications.md"},{"file":"CS3110/2020-03-03-Mutability.md"},{"file":"CS3110/2020-04-06-Red-Black-Tree.md"},{"file":"CS3110/2020-04-09-Interpreter.md"},{"file":"CS3110/2020-04-14-The-Substitution-Model.md"},{"file":"CS3110/2020-04-16-The-Environment-Model.md"}],"title":"CS3110 Functional Programming"},{"children":[{"file":"CS4780/2021-08-31-Machine-Learning-Basics.md"},{"file":"CS4780/2021-09-02-K-Nearest-Neighbors.md"},{"file":"CS4780/2021-09-07-K-means-clustering.md"},{"file":"CS4780/2021-09-09-Principal-Component-Analysis.md"},{"file":"CS4780/2021-09-14-The-Perceptron.md"},{"file":"CS4780/2021-09-16-MLE-and-MAP.md"},{"file":"CS4780/2021-09-21-Naive-Bayes.md"},{"file":"CS4780/2021-09-28-Logistic-Regression.md"},{"file":"CS4780/2021-09-30-Gradient-Descent.md"},{"file":"CS4780/2021-10-05-Important-Distributions-and-Linear-Regression.md"},{"file":"CS4780/2021-10-07-SVM---Support-Vector-Machine.md"},{"file":"CS4780/2021-10-14-Empirical-Risk-Minimization.md"},{"file":"CS4780/2021-10-19-Midterm-Review.md"},{"file":"CS4780/2021-10-26-Bias-Variance-Tradeoff.md"},{"file":"CS4780/2021-10-28-Model-Selection-Tricks.md"},{"file":"CS4780/2021-11-02-Kernels.md"},{"file":"CS4780/2021-11-04-More-on-Kernels.md"},{"file":"CS4780/2021-11-09-Decision-Tree.md"},{"file":"CS4780/2021-11-16-Bagging.md"},{"file":"CS4780/2021-11-18-Boosting.md"}],"title":"CS4780 Intro to Machine Learning"},{"children":[{"file":"CS4787/2022-08-22-Introduction.md"},{"file":"CS4787/2022-08-24-Linear-Algebra-and-NumPy.md"},{"file":"CS4787/2022-08-29-Automatic-Differentiation.md"},{"file":"CS4787/2022-08-31-Back-Propagation.md"},{"file":"CS4787/2022-09-12-Gradient-Descent.md"},{"file":"CS4787/2022-09-14-Gradient-Descent-and-Convexity.md"},{"file":"CS4787/2022-09-19-Stochastic-Gradient-Descent.md"},{"file":"CS4787/2022-09-21-Stochastic-Gradient-Descent-Improved.md"},{"file":"CS4787/2022-09-26-SGD-with-Momentum.md"},{"file":"CS4787/2022-09-28-Preconditioning-and-Element-Specific-Learning-Rate.md"},{"file":"CS4787/2022-10-03-Adaptive-Learning-Rate-and-Variance-Reduction.md"},{"file":"CS4787/2022-10-05-Sparsity-and-Dimension-Reduction.md"},{"file":"CS4787/2022-10-12-Neural-Network-Review.md"},{"file":"CS4787/2022-10-17-Accelerate-DNN-Training.md"},{"file":"CS4787/2022-10-19-Beyond-supervised-learning.md"},{"file":"CS4787/2022-10-24-Attention,-Transformers,-and-Transfer-Learning.md"}],"title":"CS4787 Principles of Large-Scale Machine Learning"},{"file":"2020-10-13-CS4820-Intro-to-Analysis-of-Algorithms.md"},{"file":"2022-02-08-ORIE4350-Game-Theory.md"}],"thumbnail":"/cornell-notes/build/cornhell-37b881e150badb60bb90a0054b1665ba.png","exports":[],"bibliography":[],"index":"index","pages":[{"slug":"2020-10-02-info1998-intro-to-machine-learning","title":"INFO1998 Intro to Machine Learning","description":"","date":"2020-10-02","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20FA","Python"],"level":1},{"slug":"2020-09-07-cs2024-c-programming","title":"CS2024 C++ Programming","description":"","date":"2020-09-07","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","CS2024","20FA"],"level":1},{"level":1,"title":"CS2112 Object-Oriented Design (Honors)"},{"slug":"2019-09-24-generics","title":"Generics","description":"","date":"2019-09-24","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","19FA","CS2112"],"level":2},{"slug":"2019-09-30-value-representation-hashing-and-generi","title":"Value Representation, Hashing, and Generics","description":"","date":"2019-09-30","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","FA19","CS2112"],"level":2},{"slug":"2019-10-08-parsing","title":"Parsing","description":"","date":"2019-10-08","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","19FA","CS2112"],"level":2},{"slug":"2019-10-17-designing-and-documenting-interfaces-an","title":"Designing and documenting interfaces and implementations","description":"","date":"2019-10-17","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","19FA","CS2112"],"level":2},{"slug":"2019-10-24-design-pattern","title":"Design Pattern","description":"","date":"2019-10-24","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","19FA","CS2112"],"level":2},{"slug":"2019-10-29-event-handlers","title":"Building GUI","description":"","date":"2019-10-29","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","19FA","CS2112"],"level":2},{"slug":"2019-11-07-concurrency","title":"Concurrency","description":"","date":"2019-11-07","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","19FA","CS2112"],"level":2},{"slug":"2019-11-12-synchronization","title":"Synchronization","description":"","date":"2019-11-12","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","19FA","CS2112"],"level":2},{"slug":"2019-11-19-graph-traversal","title":"Graph Traversal","description":"","date":"2019-11-19","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","19FA","CS2112"],"level":2},{"slug":"2019-11-20-graph-recitation","title":"Graph (Recitation)","description":"","date":"2019-11-20","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","19FA","CS2112"],"level":2},{"slug":"2019-11-21-shortest-path-algorithm","title":"shortest path algorithm","description":"","date":"2019-11-21","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","CS2112"],"level":2},{"slug":"2019-11-23-android-basics-user-interface","title":"Udacity: Android Basics","description":"","date":"2019-11-23","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Android"],"level":2},{"slug":"2019-11-26-priority-queue-and-heap","title":"Priority Queue and Heap","description":"","date":"2019-11-26","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","CS2112"],"level":2},{"slug":"2019-12-05-problem-analysis","title":"Problem Analysis","description":"","date":"2019-12-05","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","CS2112"],"level":2},{"level":1,"title":"CS3110 Functional Programming"},{"slug":"2020-01-28-functions","title":"Functions","description":"","date":"2020-01-28","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"slug":"2020-01-30-standard-data-types","title":"Standard Data Types","description":"","date":"2020-01-30","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"slug":"2020-02-04-advanced-data-types","title":"Advanced Data Types","description":"","date":"2020-02-04","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"slug":"2020-02-06-higher-order-functions","title":"Higher-Order Functions","description":"","date":"2020-02-06","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"slug":"2020-02-11-modules","title":"Modules","description":"","date":"2020-02-11","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"slug":"2020-02-13-code-reuse-with-modules","title":"Code Reuse with Modules","description":"","date":"2020-02-13","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"slug":"2020-02-18-specifications","title":"Specifications","description":"","date":"2020-02-18","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"slug":"2020-03-03-mutability","title":"Mutability","description":"","date":"2020-03-03","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"slug":"2020-04-06-red-black-tree","title":"Red Black Tree","description":"","date":"2020-04-06","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","CS3110","20SP"],"level":2},{"slug":"2020-04-09-interpreter","title":"Interpreter","description":"","date":"2020-04-09","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"slug":"2020-04-14-the-substitution-model","title":"The Substitution Model","description":"","date":"2020-04-14","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"slug":"2020-04-16-the-environment-model","title":"The Environment Model","description":"","date":"2020-04-16","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"level":1,"title":"CS4780 Intro to Machine Learning"},{"slug":"2021-08-31-machine-learning-basics","title":"Machine Learning Basics","description":"","date":"2021-08-31","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS"],"level":2},{"slug":"2021-09-02-k-nearest-neighbors","title":"K-Nearest Neighbors","description":"","date":"2021-09-02","thumbnail":"/cornell-notes/build/d2d32ed7f030408c4751b4082cc4c4fb.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-09-07-k-means-clustering","title":"K-means clustering","description":"","date":"2021-09-07","thumbnail":"/cornell-notes/build/2b624c0dfc4541e6702d7d03a35846a3.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-09-09-principal-component-analysis","title":"Principal Component Analysis","description":"","date":"2021-09-09","thumbnail":"/cornell-notes/build/0f82a0d8a1b909f3be9ff331e1e605e3.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-09-14-the-perceptron","title":"The Perceptron","description":"","date":"2021-09-14","thumbnail":"/cornell-notes/build/0561dbd9a0937d3d1decc2a2e9d7a150.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-09-16-mle-and-map","title":"MLE and MAP","description":"","date":"2021-09-16","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-09-21-naive-bayes","title":"Naive Bayes","description":"","date":"2021-09-21","thumbnail":"/cornell-notes/build/1dec3195698f490f89eb8383ef29b8c8.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-09-28-logistic-regression","title":"Logistic Regression","description":"","date":"2021-09-28","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-09-30-gradient-descent","title":"Gradient Descent","description":"","date":"2021-09-30","thumbnail":"/cornell-notes/build/e3d52da6368f919deb4783b786520acd.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-10-05-important-distributions-and-linear-regr","title":"Important Distributions and Linear Regression","description":"","date":"2021-10-05","thumbnail":"/cornell-notes/build/023faa064932bbe5ec11298e7cbdbdbd.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-10-07-svm-support-vector-machine","title":"SVM - Support Vector Machine","description":"","date":"2021-10-07","thumbnail":"/cornell-notes/build/41379864e80001dd60125813623c4915.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-10-14-empirical-risk-minimization","title":"Empirical Risk Minimization","description":"","date":"2021-10-14","thumbnail":"/cornell-notes/build/f9e37f639bf7ed7d0e0daf5d55dee992.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-10-19-midterm-review","title":"Midterm Review","description":"","date":"2021-10-19","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-10-26-bias-variance-tradeoff","title":"Bias-Variance Tradeoff","description":"","date":"2021-10-26","thumbnail":"/cornell-notes/build/92f79954ba3e60170a726689263cc46c.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-10-28-model-selection-tricks","title":"Model Selection Tricks","description":"","date":"2021-10-28","thumbnail":"/cornell-notes/build/643c4fcd86a736a95208145a3a53f8ee.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-11-02-kernels","title":"Kernels","description":"","date":"2021-11-02","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-11-04-more-on-kernels","title":"More on Kernels","description":"","date":"2021-11-04","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-11-09-decision-tree","title":"Decision Tree","description":"","date":"2021-11-09","thumbnail":"/cornell-notes/build/2f6b3cd8046659d873cef1793b421adf.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-11-16-bagging","title":"Bagging","description":"","date":"2021-11-16","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-11-18-boosting","title":"Boosting","description":"","date":"2021-11-18","thumbnail":"/cornell-notes/build/315b0684d85fc252232fdf8cba2a9c87.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"CS4787 Principles of Large-Scale Machine Learning"},{"slug":"2022-08-22-introduction","title":"Introduction","description":"","date":"2022-08-22","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-08-24-linear-algebra-and-numpy","title":"Linear Algebra and NumPy","description":"","date":"2022-08-24","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-08-29-automatic-differentiation","title":"Automatic Differentiation","description":"","date":"2022-08-29","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-08-31-back-propagation","title":"Back Propagation","description":"","date":"2022-08-31","thumbnail":"/cornell-notes/build/9a793e5d3b94eacefaeb4ada8b427898.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-09-12-gradient-descent","title":"Gradient Descent","description":"","date":"2022-09-12","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-09-14-gradient-descent-and-convexity","title":"Gradient Descent and Convexity","description":"","date":"2022-09-14","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-09-19-stochastic-gradient-descent","title":"Stochastic Gradient Descent","description":"","date":"2022-09-19","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-09-21-stochastic-gradient-descent-improved","title":"Stochastic Gradient Descent Improved","description":"","date":"2022-09-21","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-09-26-sgd-with-momentum","title":"SGD with Momentum","description":"","date":"2022-09-26","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-09-28-preconditioning-and-element-specific-le","title":"Preconditioning and Element Specific Learning Rate","description":"","date":"2022-09-28","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-10-03-adaptive-learning-rate-and-variance-red","title":"Adaptive Learning Rate and Variance Reduction","description":"","date":"2022-10-03","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-10-05-sparsity-and-dimension-reduction","title":"Sparsity and Dimension Reduction","description":"","date":"2022-10-05","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-10-12-neural-network-review","title":"Neural Network Review","description":"","date":"2022-10-12","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-10-17-accelerate-dnn-training","title":"Accelerate DNN Training","description":"","date":"2022-10-17","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-10-19-beyond-supervised-learning","title":"Beyond supervised learning","description":"","date":"2022-10-19","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-10-24-attention-transformers-and-transfer-lea","title":"Attention, Transformers, and Transfer Learning","description":"","date":"2022-10-24","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2020-10-13-cs4820-intro-to-analysis-of-algorithms","title":"CS4820 Intro to Analysis of Algorithms","description":"","date":"2020-10-13","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","CS4820"],"level":1},{"slug":"2022-02-08-orie4350-game-theory","title":"ORIE4350 Game Theory","description":"","date":"2022-02-08","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1}]}]},"page":{"version":2,"kind":"Article","sha256":"70cb7e27c03568a34b80deb0626cd6c1e07753fd1a205aa734c76165503f59ed","slug":"2020-10-02-info1998-intro-to-machine-learning","location":"/2020-10-02-INFO1998-Intro-to-Machine-Learning.md","dependencies":[],"frontmatter":{"title":"INFO1998 Intro to Machine Learning","tags":["Cornell","20FA","Python"],"date":"2020-10-02","authors":[{"nameParsed":{"literal":"Yao Lirong","given":"Yao","family":"Lirong"},"name":"Yao Lirong","affiliations":["Cornell University"],"url":"https://yao-lirong.github.io","linkedin":"https://www.linkedin.com/in/yao-lirong/","id":"contributors-myst-generated-uid-0"}],"keywords":["Cornell","CS","Yao Lirong"],"affiliations":[{"id":"Cornell University","name":"Cornell University"}],"exports":[{"format":"md","filename":"2020-10-02-INFO1998-Intro-to-Machine-Learning.md","url":"/cornell-notes/build/2020-10-02-INFO1998--e6bc3205fd7dafe80315ee3d66864e13.md"}]},"mdast":{"type":"root","children":[{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"text","value":"The goal of this course is to provide you with a high-level exposure to a wide range of Data Science techniques and Machine Learning models. From the basics of getting your Jupyter environment setup, to manipulating  and visualizing data, to building supervised and unsupervised models,  this class aims to give you the base intuition and skillset to continue  developing and working on ML projects. We hope you exit the course with  an understanding of how models and optimization techniques work, as well as have the confidence and tools to solve future problems on your own.","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"BFV2gmE5VO"}],"key":"ah3U3xrzcj"},{"type":"comment","value":"more","key":"SdX4opTfud"},{"type":"heading","depth":2,"position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"text","value":"Lec2 Data Manipulation","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"key":"z9U2LzPs5c"}],"identifier":"lec2-data-manipulation","label":"Lec2 Data Manipulation","html_id":"lec2-data-manipulation","implicit":true,"key":"hZyYNaunCR"},{"type":"heading","depth":3,"position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"text","value":"Introduction to Pandas","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"wx8hT37vNP"}],"identifier":"introduction-to-pandas","label":"Introduction to Pandas","html_id":"introduction-to-pandas","implicit":true,"key":"AImsz5G8oy"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":18,"column":1},"end":{"line":24,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"children":[{"type":"inlineCode","value":"Series","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"key":"SqywLoX7eU"},{"type":"text","value":": one dimensional array","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"key":"pHLKgU5pLJ"}],"key":"hoQKn15gGu"},{"type":"listItem","spread":true,"position":{"start":{"line":19,"column":1},"end":{"line":24,"column":1}},"children":[{"type":"inlineCode","value":"DataFrame","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"bZARVAoTDR"},{"type":"text","value":": 2-D table","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"hW0l54KJt7"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":20,"column":1},"end":{"line":24,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"children":[{"type":"text","value":"Filtering DataFrames: ","position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"key":"DShVTNHpA2"},{"type":"inlineCode","value":"loc","position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"key":"gPWP3s0jPF"}],"key":"EVtO8I0BOa"},{"type":"listItem","spread":true,"position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"children":[{"type":"text","value":"Cleaning-Up DataFrames: ","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"Ac5mIPxer7"},{"type":"inlineCode","value":"df.dropna()","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"G9z8Q2WpxM"},{"type":"text","value":", ","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"MjKkcLZeUO"},{"type":"inlineCode","value":"df[df['Open'].notnull()]","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"tZAwAC7j9p"},{"type":"text","value":" (These two methods both return a new DataFrame instead of modifying the existed one)","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"O94LqCu23U"}],"key":"gBfdJ2JN99"},{"type":"listItem","spread":true,"position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"children":[{"type":"text","value":"View DataFrames: ","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"key":"wbpmsOtXoj"},{"type":"inlineCode","value":"head","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"key":"VKTI62v5dH"},{"type":"text","value":", ","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"key":"u1I6VOsl27"},{"type":"inlineCode","value":"tail","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"key":"QiEMg7RBAe"},{"type":"text","value":", ...","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"key":"xWOXM8CK67"}],"key":"olqVSjAXYB"},{"type":"listItem","spread":true,"position":{"start":{"line":23,"column":1},"end":{"line":24,"column":1}},"children":[{"type":"text","value":"Summary Statistics: ","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"key":"Np3ry6LriE"},{"type":"inlineCode","value":"mean","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"key":"fbF49AEobW"},{"type":"text","value":", ","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"key":"GQb3ovTGvn"},{"type":"inlineCode","value":"median","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"key":"SbTEqWG03P"},{"type":"text","value":", ... ","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"key":"DJtwh4f4dd"},{"type":"inlineCode","value":"describe","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"key":"RrNIaVAPHT"}],"key":"eUNMjD2iBy"}],"key":"xrqVIyUPe1"}],"key":"bIGDBCo8aH"}],"key":"o7Wrql54a0"},{"type":"heading","depth":3,"position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"children":[{"type":"text","value":"Dealing with missing data","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"key":"osKD6A6I1k"}],"identifier":"dealing-with-missing-data","label":"Dealing with missing data","html_id":"dealing-with-missing-data","implicit":true,"key":"UVEAoxvvxx"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":27,"column":1},"end":{"line":39,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":27,"column":1},"end":{"line":33,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":27,"column":1},"end":{"line":27,"column":1}},"children":[{"type":"text","value":"Fill in some random info of our choice:","position":{"start":{"line":27,"column":1},"end":{"line":27,"column":1}},"key":"wTVlu6HVyy"}],"key":"lkSh6kLzOt"},{"type":"code","lang":"python","value":"#if we there is no record about which cabin he is in, we assume he is on the Top Deck\ndf['Cabin']=df['Cabin'].fillna('Top Deck') ","position":{"start":{"line":29,"column":1},"end":{"line":32,"column":1}},"key":"rt8wI1l48W"}],"key":"bGTRqQUG1W"},{"type":"listItem","spread":true,"position":{"start":{"line":34,"column":1},"end":{"line":37,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"children":[{"type":"text","value":"Using summary statistics: fill missing entries with median or mean","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"key":"sZvBzMtjBK"}],"key":"RHdwfj1a7J"},{"type":"paragraph","position":{"start":{"line":36,"column":1},"end":{"line":36,"column":1}},"children":[{"type":"text","value":"works well with small set","position":{"start":{"line":36,"column":1},"end":{"line":36,"column":1}},"key":"M5Fyeyx4RH"}],"key":"V1yVgR8RKv"}],"key":"SyFJ3zbEH1"},{"type":"listItem","spread":true,"position":{"start":{"line":38,"column":1},"end":{"line":39,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":38,"column":1},"end":{"line":38,"column":1}},"children":[{"type":"text","value":"Use regression and clustering: will be covered later","position":{"start":{"line":38,"column":1},"end":{"line":38,"column":1}},"key":"tmY4UjS4Fv"}],"key":"u75snvXDHP"}],"key":"iqfXdpSYrP"}],"key":"IxuFHBWesb"},{"type":"heading","depth":2,"position":{"start":{"line":40,"column":1},"end":{"line":40,"column":1}},"children":[{"type":"text","value":"Lec3 Data Visualization","position":{"start":{"line":40,"column":1},"end":{"line":40,"column":1}},"key":"Fz6r1xHZkp"}],"identifier":"lec3-data-visualization","label":"Lec3 Data Visualization","html_id":"lec3-data-visualization","implicit":true,"key":"G4y47R2XKy"},{"type":"heading","depth":3,"position":{"start":{"line":42,"column":1},"end":{"line":42,"column":1}},"children":[{"type":"text","value":"Types of Graphs","position":{"start":{"line":42,"column":1},"end":{"line":42,"column":1}},"key":"QPBLfYdrra"}],"identifier":"types-of-graphs","label":"Types of Graphs","html_id":"types-of-graphs","implicit":true,"key":"hmpCOC2lz9"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":44,"column":1},"end":{"line":46,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":44,"column":1},"end":{"line":44,"column":1}},"children":[{"type":"text","value":"Heatmap","position":{"start":{"line":44,"column":1},"end":{"line":44,"column":1}},"key":"rjggQItJF5"}],"key":"kXHpLFpmgF"},{"type":"listItem","spread":true,"position":{"start":{"line":45,"column":1},"end":{"line":46,"column":1}},"children":[{"type":"text","value":"Correlation Plots","position":{"start":{"line":45,"column":1},"end":{"line":45,"column":1}},"key":"G6k8fbNYbJ"}],"key":"SjkDkxBDZn"}],"key":"GlBZoiycjI"},{"type":"heading","depth":3,"position":{"start":{"line":47,"column":1},"end":{"line":47,"column":1}},"children":[{"type":"text","value":"Coloring Graphs","position":{"start":{"line":47,"column":1},"end":{"line":47,"column":1}},"key":"m1pVYJ6t4A"}],"identifier":"coloring-graphs","label":"Coloring Graphs","html_id":"coloring-graphs","implicit":true,"key":"ZPm7XTITp5"},{"type":"paragraph","position":{"start":{"line":49,"column":1},"end":{"line":49,"column":1}},"children":[{"type":"inlineCode","value":"plt.scatter(Longitude, Latitude, c=Temp.values.ravel(),cmap=plt.cm.OrRd)","position":{"start":{"line":49,"column":1},"end":{"line":49,"column":1}},"key":"no2UpvK2uv"},{"type":"text","value":" color a scattered plot based on values of ","position":{"start":{"line":49,"column":1},"end":{"line":49,"column":1}},"key":"a1WSJ9w5sc"},{"type":"inlineCode","value":"Temp","position":{"start":{"line":49,"column":1},"end":{"line":49,"column":1}},"key":"GKIpuTl0IF"},{"type":"text","value":" with color scheme ","position":{"start":{"line":49,"column":1},"end":{"line":49,"column":1}},"key":"WysB46nB5R"},{"type":"inlineCode","value":"cm.OrRd","position":{"start":{"line":49,"column":1},"end":{"line":49,"column":1}},"key":"TBj6SIQwi3"},{"type":"text","value":". Find more color schemes from ","position":{"start":{"line":49,"column":1},"end":{"line":49,"column":1}},"key":"UBBpxQKzcO"},{"type":"link","url":"https://matplotlib.org/3.1.0/tutorials/colors/colormaps.html","position":{"start":{"line":49,"column":1},"end":{"line":49,"column":1}},"children":[{"type":"text","value":"matplotlib manual","position":{"start":{"line":49,"column":1},"end":{"line":49,"column":1}},"key":"rVwWjOP043"}],"urlSource":"https://matplotlib.org/3.1.0/tutorials/colors/colormaps.html","key":"FKAKcxaVmR"},{"type":"text","value":".","position":{"start":{"line":49,"column":1},"end":{"line":49,"column":1}},"key":"zbR20junhE"}],"key":"FKfZUUHk3g"},{"type":"heading","depth":2,"position":{"start":{"line":51,"column":1},"end":{"line":51,"column":1}},"children":[{"type":"text","value":"Lec4 Linear Regression","position":{"start":{"line":51,"column":1},"end":{"line":51,"column":1}},"key":"OsM7CXNKOe"}],"identifier":"lec4-linear-regression","label":"Lec4 Linear Regression","html_id":"lec4-linear-regression","implicit":true,"key":"NdI58S2wIg"},{"type":"heading","depth":3,"position":{"start":{"line":53,"column":1},"end":{"line":53,"column":1}},"children":[{"type":"text","value":"Preparing Data","position":{"start":{"line":53,"column":1},"end":{"line":53,"column":1}},"key":"ZdHBXv7r3t"}],"identifier":"preparing-data","label":"Preparing Data","html_id":"preparing-data","implicit":true,"key":"Xsb98yiLFP"},{"type":"code","lang":"python","value":"from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\n# X must be a table (in case there are multiple x in y = a1*x1 + a2*x2 + ... + k)\nX = data[['cost','compl_4']] \n# Y must be one column\nY = data['median_earnings'] \n\nfrom sklearn.model_selection import train_test_split\n# test is 20% of all data\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)","position":{"start":{"line":55,"column":1},"end":{"line":66,"column":1}},"key":"aN2w1K2oIF"},{"type":"heading","depth":3,"position":{"start":{"line":68,"column":1},"end":{"line":68,"column":1}},"children":[{"type":"text","value":"Predicting and Fitting","position":{"start":{"line":68,"column":1},"end":{"line":68,"column":1}},"key":"c7RJkWmDjg"}],"identifier":"predicting-and-fitting","label":"Predicting and Fitting","html_id":"predicting-and-fitting","implicit":true,"key":"fraqotz5Kb"},{"type":"code","lang":"python","value":"# creates Linear Regression model \nLR = LinearRegression()\n# note LR is an object by calling fit, we set all of its coefficients\nLR.fit(x_train, y_train)\n# predict() returns the predicted value\ny_predicted = LR.predict(x_test)\n# score(x,y') first computes the predicted value y based on x and our model, then compare it with y'\nscore = LR.score(x_test,y_test)","position":{"start":{"line":70,"column":1},"end":{"line":79,"column":1}},"key":"N6IK9xnjZd"},{"type":"heading","depth":3,"position":{"start":{"line":81,"column":1},"end":{"line":81,"column":1}},"children":[{"type":"text","value":"Describing the Model","position":{"start":{"line":81,"column":1},"end":{"line":81,"column":1}},"key":"Vxb1fqnTM8"}],"identifier":"describing-the-model","label":"Describing the Model","html_id":"describing-the-model","implicit":true,"key":"bS1aJ0bgrc"},{"type":"code","lang":"python","value":"# Gives a comprehensive view of Y = a1*x1 + a2*x2 + ... + k\nLR?\n\n# coefficients of x (a1, a2, ...)\nLR.coef_\n\n# intercept k\nLR.intercept_","position":{"start":{"line":83,"column":1},"end":{"line":92,"column":1}},"key":"ARRZSV2GK2"},{"type":"heading","depth":2,"position":{"start":{"line":94,"column":1},"end":{"line":94,"column":1}},"children":[{"type":"text","value":"Lec5 Measuring Model’s Accuracy","position":{"start":{"line":94,"column":1},"end":{"line":94,"column":1}},"key":"nPV3UfpPMd"}],"identifier":"lec5-measuring-models-accuracy","label":"Lec5 Measuring Model’s Accuracy","html_id":"lec5-measuring-models-accuracy","implicit":true,"key":"ETFaDKj3uD"},{"type":"paragraph","position":{"start":{"line":96,"column":1},"end":{"line":96,"column":1}},"children":[{"type":"text","value":"When determining accuracy, usually want to compare our model to a baseline. Therefore, instead of comparing our model’s prediction to each specific ","position":{"start":{"line":96,"column":1},"end":{"line":96,"column":1}},"key":"WSTofGl7KS"},{"type":"inlineCode","value":"y","position":{"start":{"line":96,"column":1},"end":{"line":96,"column":1}},"key":"Pv29PTWsRx"},{"type":"text","value":" value, we compare it with the mean ","position":{"start":{"line":96,"column":1},"end":{"line":96,"column":1}},"key":"mP2qXKJFH7"},{"type":"inlineCode","value":"y","position":{"start":{"line":96,"column":1},"end":{"line":96,"column":1}},"key":"PclYDKoplc"},{"type":"text","value":" value.","position":{"start":{"line":96,"column":1},"end":{"line":96,"column":1}},"key":"ShMllOUyeg"}],"key":"rGJDMuTPeV"},{"type":"code","lang":"python","value":"from sklearn.metrics import mean_squared_error\ncelcius_MSE = mean_squared_error(y_test, celcius_predictions)\n\ntest_goal_mean = y_test.mean()\nbaseline = np.full((len(celcius_predictions),), test_goal_mean)\nbaseline_MSE = mean_squared_error(baseline, celcius_predictions)","position":{"start":{"line":98,"column":1},"end":{"line":105,"column":1}},"key":"eUg8tNh1T7"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":107,"column":1},"end":{"line":109,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":107,"column":1},"end":{"line":107,"column":1}},"children":[{"type":"text","value":"overfitting: too specific to the data given, doesn’t predict any other data","position":{"start":{"line":107,"column":1},"end":{"line":107,"column":1}},"key":"NHxSLlokl0"}],"key":"YfDoJ2Uizg"},{"type":"listItem","spread":true,"position":{"start":{"line":108,"column":1},"end":{"line":109,"column":1}},"children":[{"type":"text","value":"underfitting: no matter what data you use to train this model, it gives the same curve, so it doesn’t have prediction power either because it doesn’t show any pattern of the data.","position":{"start":{"line":108,"column":1},"end":{"line":108,"column":1}},"key":"O8R1AGUJi1"}],"key":"C7AYY2MRx3"}],"key":"W3ydEJI7cl"},{"type":"heading","depth":2,"position":{"start":{"line":110,"column":1},"end":{"line":110,"column":1}},"children":[{"type":"text","value":"Lec6 Classifiers","position":{"start":{"line":110,"column":1},"end":{"line":110,"column":1}},"key":"ihWDLQAare"}],"identifier":"lec6-classifiers","label":"Lec6 Classifiers","html_id":"lec6-classifiers","implicit":true,"key":"qFBQhnA4X1"},{"type":"paragraph","position":{"start":{"line":112,"column":1},"end":{"line":112,"column":1}},"children":[{"type":"text","value":"Linear regression is used to predict the value of a continuous variable. Classifiers are used to predict ","position":{"start":{"line":112,"column":1},"end":{"line":112,"column":1}},"key":"TnmZsFdB0i"},{"type":"strong","position":{"start":{"line":112,"column":1},"end":{"line":112,"column":1}},"children":[{"type":"text","value":"categorical or binary variables","position":{"start":{"line":112,"column":1},"end":{"line":112,"column":1}},"key":"OWNOBcnS5H"}],"key":"ruANi2vVvj"},{"type":"text","value":".","position":{"start":{"line":112,"column":1},"end":{"line":112,"column":1}},"key":"IrDiWZQ5VW"}],"key":"gdC1ftSb4V"},{"type":"heading","depth":3,"position":{"start":{"line":114,"column":1},"end":{"line":114,"column":1}},"children":[{"type":"text","value":"KNN","position":{"start":{"line":114,"column":1},"end":{"line":114,"column":1}},"key":"lifAXJBTKe"}],"identifier":"knn","label":"KNN","html_id":"knn","implicit":true,"key":"xf6FEtUhi4"},{"type":"code","lang":"python","value":"from sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nx_train, x_test, y_train, y_test = train_test_split(X,Y, test_size=0.2)\n\nk = 10\nmodel = KNeighborsClassifier(k) # specify k nearest elements\nmodel.fit(x_train,y_train)\npredictions = model.predict(x_test)","position":{"start":{"line":116,"column":1},"end":{"line":125,"column":1}},"key":"Xw7lJM52m8"},{"type":"heading","depth":2,"position":{"start":{"line":127,"column":1},"end":{"line":127,"column":1}},"children":[{"type":"text","value":"Lec7 Other Supervised Learning Models","position":{"start":{"line":127,"column":1},"end":{"line":127,"column":1}},"key":"NqZs9xlMNb"}],"identifier":"lec7-other-supervised-learning-models","label":"Lec7 Other Supervised Learning Models","html_id":"lec7-other-supervised-learning-models","implicit":true,"key":"jUrTjom6m6"},{"type":"heading","depth":3,"position":{"start":{"line":129,"column":1},"end":{"line":129,"column":1}},"children":[{"type":"text","value":"Decision Trees","position":{"start":{"line":129,"column":1},"end":{"line":129,"column":1}},"key":"Zezez6j2YJ"}],"identifier":"decision-trees","label":"Decision Trees","html_id":"decision-trees","implicit":true,"key":"xiddzxSekT"},{"type":"code","lang":"python","value":"from sklearn import tree\nfrom sklearn.tree import DecisionTreeClassifier\nmodel = tree.DecisionTreeClassifier(max_depth=5)","position":{"start":{"line":131,"column":1},"end":{"line":135,"column":1}},"key":"FMp4ayAPvm"},{"type":"paragraph","position":{"start":{"line":137,"column":1},"end":{"line":137,"column":1}},"children":[{"type":"text","value":"How to reduce overfitting?","position":{"start":{"line":137,"column":1},"end":{"line":137,"column":1}},"key":"QFtCK3BOL6"}],"key":"pibchqLF3Y"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":139,"column":1},"end":{"line":141,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":139,"column":1},"end":{"line":139,"column":1}},"children":[{"type":"text","value":"Reduce levels of trees","position":{"start":{"line":139,"column":1},"end":{"line":139,"column":1}},"key":"xCgWXrZzaE"}],"key":"yFGPh47Kfb"},{"type":"listItem","spread":true,"position":{"start":{"line":140,"column":1},"end":{"line":141,"column":1}},"children":[{"type":"text","value":"Train multiple decision trees (maybe one for each training data) and take its average as final result","position":{"start":{"line":140,"column":1},"end":{"line":140,"column":1}},"key":"BP9q2hslQP"}],"key":"VuPJW4DWZw"}],"key":"E2g0ED0pZJ"},{"type":"heading","depth":3,"position":{"start":{"line":142,"column":1},"end":{"line":142,"column":1}},"children":[{"type":"text","value":"Logistic Regression","position":{"start":{"line":142,"column":1},"end":{"line":142,"column":1}},"key":"nQNp0T6Emd"}],"identifier":"logistic-regression","label":"Logistic Regression","html_id":"logistic-regression","implicit":true,"key":"tckEj2Vkcj"},{"type":"paragraph","position":{"start":{"line":144,"column":1},"end":{"line":144,"column":1}},"children":[{"type":"text","value":"Value always between 0 and 1. Accept if value higher than threshold, reject if lower.","position":{"start":{"line":144,"column":1},"end":{"line":144,"column":1}},"key":"M6iFo6g1vg"}],"key":"LhzT6rCKk0"},{"type":"heading","depth":3,"position":{"start":{"line":146,"column":1},"end":{"line":146,"column":1}},"children":[{"type":"text","value":"K-fold Cross Validation","position":{"start":{"line":146,"column":1},"end":{"line":146,"column":1}},"key":"yZOOYHI7Am"}],"identifier":"k-fold-cross-validation","label":"K-fold Cross Validation","html_id":"k-fold-cross-validation","implicit":true,"key":"C5o4JNbBUp"},{"type":"paragraph","position":{"start":{"line":148,"column":1},"end":{"line":148,"column":1}},"children":[{"type":"text","value":"Rather than doing test-train split only once, we do it k times: First separate our sample into k pieces and each time we take one of them as test set, the others as training set. Use ","position":{"start":{"line":148,"column":1},"end":{"line":148,"column":1}},"key":"EnJTv8fDxC"},{"type":"inlineCode","value":"from sklearn.model_selection import KFold","position":{"start":{"line":148,"column":1},"end":{"line":148,"column":1}},"key":"gAkyLwhUQO"},{"type":"text","value":" to achieve this. Calculate a score for each of the split and take its average as the final score. This score is usually closer to real errors.","position":{"start":{"line":148,"column":1},"end":{"line":148,"column":1}},"key":"LBwCVKWy4o"}],"key":"DIzbUZuYSQ"},{"type":"code","lang":"python","value":"from sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error, accuracy_score\n\nincX = inc_data[['education.num']]\nincY = inc_data['income']\n\nkf = KFold(n_splits = 5)\naccuracy = 0\nfor train_index, test_index in kf.split(incX):\n    X_train = incX.iloc[train_index]\n    Y_train = incY.iloc[train_index]\n    X_test = incX.iloc[test_index]\n    Y_test = incY.iloc[test_index]\n    \n    # best_depth 是我们前一题找到的使分最高的 depth level of decision tree\n    model = tree.DecisionTreeClassifier (max_depth = best_depth)\n    model.fit(X_train, Y_train)\n    pred_test = model.predict(X_test)\n    accuracy += accuracy_score(Y_test, pred_test)\n    \naccuracy /= 5\nprint(accuracy)","position":{"start":{"line":150,"column":1},"end":{"line":173,"column":1}},"key":"PtNvomii2E"},{"type":"heading","depth":2,"position":{"start":{"line":175,"column":1},"end":{"line":175,"column":1}},"children":[{"type":"text","value":"Lec9 Unsupervised Learning","position":{"start":{"line":175,"column":1},"end":{"line":175,"column":1}},"key":"VJ244JmaNF"}],"identifier":"lec9-unsupervised-learning","label":"Lec9 Unsupervised Learning","html_id":"lec9-unsupervised-learning","implicit":true,"key":"y0CIEUvJOb"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":177,"column":1},"end":{"line":179,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":177,"column":1},"end":{"line":177,"column":1}},"children":[{"type":"text","value":"Supervised Learning: The desired solution (target) is also included in the dataset","position":{"start":{"line":177,"column":1},"end":{"line":177,"column":1}},"key":"LyV2hjWJYV"}],"key":"BhlwagTRAZ"},{"type":"listItem","spread":true,"position":{"start":{"line":178,"column":1},"end":{"line":179,"column":1}},"children":[{"type":"text","value":"Unsupervised Learning: The training data is unlabeled and algorithm tries to learn by itself","position":{"start":{"line":178,"column":1},"end":{"line":178,"column":1}},"key":"jAe90rCsde"}],"key":"kgtu9D22Xb"}],"key":"e3rjqwJ3E7"},{"type":"heading","depth":3,"position":{"start":{"line":180,"column":1},"end":{"line":180,"column":1}},"children":[{"type":"text","value":"Hierarchical Clustering","position":{"start":{"line":180,"column":1},"end":{"line":180,"column":1}},"key":"BlVo5V3juh"}],"identifier":"hierarchical-clustering","label":"Hierarchical Clustering","html_id":"hierarchical-clustering","implicit":true,"key":"usnnnKFkUb"},{"type":"paragraph","position":{"start":{"line":182,"column":1},"end":{"line":182,"column":1}},"children":[{"type":"text","value":"Hierarchical clustering groups observations into multiple levels of  sets; the top-level set includes all of the data, and the bottom-level  sets contain individual observations. The levels in between contain sets of observations with similar features.","position":{"start":{"line":182,"column":1},"end":{"line":182,"column":1}},"key":"YnHUdh0PKT"}],"key":"MHzIKgQHk9"},{"type":"code","lang":"python","value":"from sklearn.preprocessing import StandardScaler\nfrom scipy.cluster.hierarchy import dendrogram, linkage\nfrom matplotlib import pyplot as plt\n\n# Standardize features by removing the mean and scaling to unit variance\ndata = StandardScaler().fit_transform(data)\n# build our model from data\nclust = linkage(data) \n# draw the dendrogram visulization\ndendrogram(clust)\nplt.show()","position":{"start":{"line":184,"column":1},"end":{"line":196,"column":1}},"key":"TtAZgU7q0X"},{"type":"heading","depth":3,"position":{"start":{"line":198,"column":1},"end":{"line":198,"column":1}},"children":[{"type":"text","value":"K-Means Clustering","position":{"start":{"line":198,"column":1},"end":{"line":198,"column":1}},"key":"a5faJPpiZ9"}],"identifier":"k-means-clustering","label":"K-Means Clustering","html_id":"k-means-clustering","implicit":true,"key":"LginNGRmp8"},{"type":"paragraph","position":{"start":{"line":200,"column":1},"end":{"line":200,"column":1}},"children":[{"type":"text","value":"We want to cluster the data into k groups. We first randomly choose k points in this dataset. Then we assign other data points to the group they are closest to. After assigning all data points to some group, we recompute the center of each group by taking the means of all points in that group. Repeat this process until no points change group assignment after one iteration.","position":{"start":{"line":200,"column":1},"end":{"line":200,"column":1}},"key":"vXHVE9L8oa"}],"key":"hrZHsVdjYK"},{"type":"code","lang":"python","value":"from sklearn import cluster\nk = 3\nkmeans = cluster.KMeans(n_clusters = k) #cluster into k groups\nkmeans.fit(data)","position":{"start":{"line":202,"column":1},"end":{"line":207,"column":1}},"key":"FOHmRp2syS"}],"key":"JXtB8cMwOH"}],"key":"vQ30DP490o"},"references":{"cite":{"order":[],"data":{}}},"footer":{"navigation":{"prev":{"title":"Incomplete CS Notes @ Cornell","url":"/","group":"Incomplete CS Notes @ Cornell"},"next":{"title":"CS2024 C++ Programming","url":"/2020-09-07-cs2024-c-programming","group":"Incomplete CS Notes @ Cornell"}}},"domain":"http://localhost:3000"},"project":{"title":"Incomplete CS Notes @ Cornell","description":"This is a complete collection of course notes I've taken when studying CS at Cornell University","authors":[{"nameParsed":{"literal":"Yao Lirong","given":"Yao","family":"Lirong"},"name":"Yao Lirong","affiliations":["Cornell University"],"url":"https://yao-lirong.github.io","linkedin":"https://www.linkedin.com/in/yao-lirong/","id":"contributors-myst-generated-uid-0"}],"keywords":["Cornell","CS","Yao Lirong"],"affiliations":[{"id":"Cornell University","name":"Cornell University"}],"id":"dbd3e509-63c9-4982-a7c3-5cf505dc3c02","toc":[{"file":"index.md"},{"file":"2020-10-02-INFO1998-Intro-to-Machine-Learning.md"},{"file":"2020-09-07-CS2024-C++-Programming.md"},{"children":[{"file":"CS2112/2019-09-24-Generics.md"},{"file":"CS2112/2019-09-30-Value-Representation,-Hashing,-and-Generics.md"},{"file":"CS2112/2019-10-08-Parsing.md"},{"file":"CS2112/2019-10-17-Designing-and-documenting-interfaces-and-implementations.md"},{"file":"CS2112/2019-10-24-Design-Pattern.md"},{"file":"CS2112/2019-10-29 Event Handlers.md"},{"file":"CS2112/2019-11-07-Concurrency.md"},{"file":"CS2112/2019-11-12-synchronization.md"},{"file":"CS2112/2019-11-19-Graph-Traversal.md"},{"file":"CS2112/2019-11-20-Graph-(Recitation).md"},{"file":"CS2112/2019-11-21-shortest-path-algorithm.md"},{"file":"CS2112/2019-11-23-Android-Basics-User-Interface.md"},{"file":"CS2112/2019-11-26-Priority-Queue-and-Heap.md"},{"file":"CS2112/2019-12-05-Problem-Analysis.md"}],"title":"CS2112 Object-Oriented Design (Honors)"},{"children":[{"file":"CS3110/2020-01-28-Functions.md"},{"file":"CS3110/2020-01-30-Standard-Data-Types.md"},{"file":"CS3110/2020-02-04-Advanced-Data-Types.md"},{"file":"CS3110/2020-02-06-Higher-Order-Functions.md"},{"file":"CS3110/2020-02-11-Modules.md"},{"file":"CS3110/2020-02-13-Code-Reuse-with-Modules.md"},{"file":"CS3110/2020-02-18-Specifications.md"},{"file":"CS3110/2020-03-03-Mutability.md"},{"file":"CS3110/2020-04-06-Red-Black-Tree.md"},{"file":"CS3110/2020-04-09-Interpreter.md"},{"file":"CS3110/2020-04-14-The-Substitution-Model.md"},{"file":"CS3110/2020-04-16-The-Environment-Model.md"}],"title":"CS3110 Functional Programming"},{"children":[{"file":"CS4780/2021-08-31-Machine-Learning-Basics.md"},{"file":"CS4780/2021-09-02-K-Nearest-Neighbors.md"},{"file":"CS4780/2021-09-07-K-means-clustering.md"},{"file":"CS4780/2021-09-09-Principal-Component-Analysis.md"},{"file":"CS4780/2021-09-14-The-Perceptron.md"},{"file":"CS4780/2021-09-16-MLE-and-MAP.md"},{"file":"CS4780/2021-09-21-Naive-Bayes.md"},{"file":"CS4780/2021-09-28-Logistic-Regression.md"},{"file":"CS4780/2021-09-30-Gradient-Descent.md"},{"file":"CS4780/2021-10-05-Important-Distributions-and-Linear-Regression.md"},{"file":"CS4780/2021-10-07-SVM---Support-Vector-Machine.md"},{"file":"CS4780/2021-10-14-Empirical-Risk-Minimization.md"},{"file":"CS4780/2021-10-19-Midterm-Review.md"},{"file":"CS4780/2021-10-26-Bias-Variance-Tradeoff.md"},{"file":"CS4780/2021-10-28-Model-Selection-Tricks.md"},{"file":"CS4780/2021-11-02-Kernels.md"},{"file":"CS4780/2021-11-04-More-on-Kernels.md"},{"file":"CS4780/2021-11-09-Decision-Tree.md"},{"file":"CS4780/2021-11-16-Bagging.md"},{"file":"CS4780/2021-11-18-Boosting.md"}],"title":"CS4780 Intro to Machine Learning"},{"children":[{"file":"CS4787/2022-08-22-Introduction.md"},{"file":"CS4787/2022-08-24-Linear-Algebra-and-NumPy.md"},{"file":"CS4787/2022-08-29-Automatic-Differentiation.md"},{"file":"CS4787/2022-08-31-Back-Propagation.md"},{"file":"CS4787/2022-09-12-Gradient-Descent.md"},{"file":"CS4787/2022-09-14-Gradient-Descent-and-Convexity.md"},{"file":"CS4787/2022-09-19-Stochastic-Gradient-Descent.md"},{"file":"CS4787/2022-09-21-Stochastic-Gradient-Descent-Improved.md"},{"file":"CS4787/2022-09-26-SGD-with-Momentum.md"},{"file":"CS4787/2022-09-28-Preconditioning-and-Element-Specific-Learning-Rate.md"},{"file":"CS4787/2022-10-03-Adaptive-Learning-Rate-and-Variance-Reduction.md"},{"file":"CS4787/2022-10-05-Sparsity-and-Dimension-Reduction.md"},{"file":"CS4787/2022-10-12-Neural-Network-Review.md"},{"file":"CS4787/2022-10-17-Accelerate-DNN-Training.md"},{"file":"CS4787/2022-10-19-Beyond-supervised-learning.md"},{"file":"CS4787/2022-10-24-Attention,-Transformers,-and-Transfer-Learning.md"}],"title":"CS4787 Principles of Large-Scale Machine Learning"},{"file":"2020-10-13-CS4820-Intro-to-Analysis-of-Algorithms.md"},{"file":"2022-02-08-ORIE4350-Game-Theory.md"}],"thumbnail":"/cornell-notes/build/cornhell-37b881e150badb60bb90a0054b1665ba.png","exports":[],"bibliography":[],"index":"index","pages":[{"slug":"2020-10-02-info1998-intro-to-machine-learning","title":"INFO1998 Intro to Machine Learning","description":"","date":"2020-10-02","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20FA","Python"],"level":1},{"slug":"2020-09-07-cs2024-c-programming","title":"CS2024 C++ Programming","description":"","date":"2020-09-07","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","CS2024","20FA"],"level":1},{"level":1,"title":"CS2112 Object-Oriented Design (Honors)"},{"slug":"2019-09-24-generics","title":"Generics","description":"","date":"2019-09-24","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","19FA","CS2112"],"level":2},{"slug":"2019-09-30-value-representation-hashing-and-generi","title":"Value Representation, Hashing, and Generics","description":"","date":"2019-09-30","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","FA19","CS2112"],"level":2},{"slug":"2019-10-08-parsing","title":"Parsing","description":"","date":"2019-10-08","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","19FA","CS2112"],"level":2},{"slug":"2019-10-17-designing-and-documenting-interfaces-an","title":"Designing and documenting interfaces and implementations","description":"","date":"2019-10-17","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","19FA","CS2112"],"level":2},{"slug":"2019-10-24-design-pattern","title":"Design Pattern","description":"","date":"2019-10-24","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","19FA","CS2112"],"level":2},{"slug":"2019-10-29-event-handlers","title":"Building GUI","description":"","date":"2019-10-29","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","19FA","CS2112"],"level":2},{"slug":"2019-11-07-concurrency","title":"Concurrency","description":"","date":"2019-11-07","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","19FA","CS2112"],"level":2},{"slug":"2019-11-12-synchronization","title":"Synchronization","description":"","date":"2019-11-12","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","19FA","CS2112"],"level":2},{"slug":"2019-11-19-graph-traversal","title":"Graph Traversal","description":"","date":"2019-11-19","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","19FA","CS2112"],"level":2},{"slug":"2019-11-20-graph-recitation","title":"Graph (Recitation)","description":"","date":"2019-11-20","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","19FA","CS2112"],"level":2},{"slug":"2019-11-21-shortest-path-algorithm","title":"shortest path algorithm","description":"","date":"2019-11-21","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","CS2112"],"level":2},{"slug":"2019-11-23-android-basics-user-interface","title":"Udacity: Android Basics","description":"","date":"2019-11-23","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Android"],"level":2},{"slug":"2019-11-26-priority-queue-and-heap","title":"Priority Queue and Heap","description":"","date":"2019-11-26","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","CS2112"],"level":2},{"slug":"2019-12-05-problem-analysis","title":"Problem Analysis","description":"","date":"2019-12-05","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","CS2112"],"level":2},{"level":1,"title":"CS3110 Functional Programming"},{"slug":"2020-01-28-functions","title":"Functions","description":"","date":"2020-01-28","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"slug":"2020-01-30-standard-data-types","title":"Standard Data Types","description":"","date":"2020-01-30","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"slug":"2020-02-04-advanced-data-types","title":"Advanced Data Types","description":"","date":"2020-02-04","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"slug":"2020-02-06-higher-order-functions","title":"Higher-Order Functions","description":"","date":"2020-02-06","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"slug":"2020-02-11-modules","title":"Modules","description":"","date":"2020-02-11","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"slug":"2020-02-13-code-reuse-with-modules","title":"Code Reuse with Modules","description":"","date":"2020-02-13","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"slug":"2020-02-18-specifications","title":"Specifications","description":"","date":"2020-02-18","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"slug":"2020-03-03-mutability","title":"Mutability","description":"","date":"2020-03-03","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"slug":"2020-04-06-red-black-tree","title":"Red Black Tree","description":"","date":"2020-04-06","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","CS3110","20SP"],"level":2},{"slug":"2020-04-09-interpreter","title":"Interpreter","description":"","date":"2020-04-09","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"slug":"2020-04-14-the-substitution-model","title":"The Substitution Model","description":"","date":"2020-04-14","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"slug":"2020-04-16-the-environment-model","title":"The Environment Model","description":"","date":"2020-04-16","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","20SP","CS3110"],"level":2},{"level":1,"title":"CS4780 Intro to Machine Learning"},{"slug":"2021-08-31-machine-learning-basics","title":"Machine Learning Basics","description":"","date":"2021-08-31","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS"],"level":2},{"slug":"2021-09-02-k-nearest-neighbors","title":"K-Nearest Neighbors","description":"","date":"2021-09-02","thumbnail":"/cornell-notes/build/d2d32ed7f030408c4751b4082cc4c4fb.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-09-07-k-means-clustering","title":"K-means clustering","description":"","date":"2021-09-07","thumbnail":"/cornell-notes/build/2b624c0dfc4541e6702d7d03a35846a3.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-09-09-principal-component-analysis","title":"Principal Component Analysis","description":"","date":"2021-09-09","thumbnail":"/cornell-notes/build/0f82a0d8a1b909f3be9ff331e1e605e3.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-09-14-the-perceptron","title":"The Perceptron","description":"","date":"2021-09-14","thumbnail":"/cornell-notes/build/0561dbd9a0937d3d1decc2a2e9d7a150.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-09-16-mle-and-map","title":"MLE and MAP","description":"","date":"2021-09-16","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-09-21-naive-bayes","title":"Naive Bayes","description":"","date":"2021-09-21","thumbnail":"/cornell-notes/build/1dec3195698f490f89eb8383ef29b8c8.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-09-28-logistic-regression","title":"Logistic Regression","description":"","date":"2021-09-28","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-09-30-gradient-descent","title":"Gradient Descent","description":"","date":"2021-09-30","thumbnail":"/cornell-notes/build/e3d52da6368f919deb4783b786520acd.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-10-05-important-distributions-and-linear-regr","title":"Important Distributions and Linear Regression","description":"","date":"2021-10-05","thumbnail":"/cornell-notes/build/023faa064932bbe5ec11298e7cbdbdbd.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-10-07-svm-support-vector-machine","title":"SVM - Support Vector Machine","description":"","date":"2021-10-07","thumbnail":"/cornell-notes/build/41379864e80001dd60125813623c4915.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-10-14-empirical-risk-minimization","title":"Empirical Risk Minimization","description":"","date":"2021-10-14","thumbnail":"/cornell-notes/build/f9e37f639bf7ed7d0e0daf5d55dee992.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-10-19-midterm-review","title":"Midterm Review","description":"","date":"2021-10-19","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-10-26-bias-variance-tradeoff","title":"Bias-Variance Tradeoff","description":"","date":"2021-10-26","thumbnail":"/cornell-notes/build/92f79954ba3e60170a726689263cc46c.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-10-28-model-selection-tricks","title":"Model Selection Tricks","description":"","date":"2021-10-28","thumbnail":"/cornell-notes/build/643c4fcd86a736a95208145a3a53f8ee.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-11-02-kernels","title":"Kernels","description":"","date":"2021-11-02","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-11-04-more-on-kernels","title":"More on Kernels","description":"","date":"2021-11-04","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-11-09-decision-tree","title":"Decision Tree","description":"","date":"2021-11-09","thumbnail":"/cornell-notes/build/2f6b3cd8046659d873cef1793b421adf.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-11-16-bagging","title":"Bagging","description":"","date":"2021-11-16","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"2021-11-18-boosting","title":"Boosting","description":"","date":"2021-11-18","thumbnail":"/cornell-notes/build/315b0684d85fc252232fdf8cba2a9c87.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"CS4787 Principles of Large-Scale Machine Learning"},{"slug":"2022-08-22-introduction","title":"Introduction","description":"","date":"2022-08-22","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-08-24-linear-algebra-and-numpy","title":"Linear Algebra and NumPy","description":"","date":"2022-08-24","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-08-29-automatic-differentiation","title":"Automatic Differentiation","description":"","date":"2022-08-29","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-08-31-back-propagation","title":"Back Propagation","description":"","date":"2022-08-31","thumbnail":"/cornell-notes/build/9a793e5d3b94eacefaeb4ada8b427898.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-09-12-gradient-descent","title":"Gradient Descent","description":"","date":"2022-09-12","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-09-14-gradient-descent-and-convexity","title":"Gradient Descent and Convexity","description":"","date":"2022-09-14","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-09-19-stochastic-gradient-descent","title":"Stochastic Gradient Descent","description":"","date":"2022-09-19","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-09-21-stochastic-gradient-descent-improved","title":"Stochastic Gradient Descent Improved","description":"","date":"2022-09-21","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-09-26-sgd-with-momentum","title":"SGD with Momentum","description":"","date":"2022-09-26","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-09-28-preconditioning-and-element-specific-le","title":"Preconditioning and Element Specific Learning Rate","description":"","date":"2022-09-28","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-10-03-adaptive-learning-rate-and-variance-red","title":"Adaptive Learning Rate and Variance Reduction","description":"","date":"2022-10-03","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-10-05-sparsity-and-dimension-reduction","title":"Sparsity and Dimension Reduction","description":"","date":"2022-10-05","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-10-12-neural-network-review","title":"Neural Network Review","description":"","date":"2022-10-12","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-10-17-accelerate-dnn-training","title":"Accelerate DNN Training","description":"","date":"2022-10-17","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-10-19-beyond-supervised-learning","title":"Beyond supervised learning","description":"","date":"2022-10-19","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2022-10-24-attention-transformers-and-transfer-lea","title":"Attention, Transformers, and Transfer Learning","description":"","date":"2022-10-24","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CS4787"],"level":2},{"slug":"2020-10-13-cs4820-intro-to-analysis-of-algorithms","title":"CS4820 Intro to Analysis of Algorithms","description":"","date":"2020-10-13","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["Cornell","CS4820"],"level":1},{"slug":"2022-02-08-orie4350-game-theory","title":"ORIE4350 Game Theory","description":"","date":"2022-02-08","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1}]}}},"actionData":null,"errors":null},"future":{"unstable_dev":false,"unstable_postcss":false,"unstable_tailwind":false,"v2_errorBoundary":true,"v2_headers":true,"v2_meta":true,"v2_normalizeFormMethod":true,"v2_routeConvention":true}};</script><script type="module" async="">import "/cornell-notes/build/manifest-7CA79D5B.js";
import * as route0 from "/cornell-notes/build/root-LY5YATWI.js";
import * as route1 from "/cornell-notes/build/routes/$-RAODST7L.js";
window.__remixRouteModules = {"root":route0,"routes/$":route1};

import("/cornell-notes/build/entry.client-UNPC4GT3.js");</script></body></html>